{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get one symbol nakeds for `NSE`\n",
    "***\n",
    "\n",
    "# !!! `REMEMBER TO REMOVE PREVIOUS EARLIEST NAKEDS PICKLES` !!!\n",
    "\n",
    "THIS NEEDS TO CHANGE TO `EARLIEST NAKEDS` !!!\n",
    "\n",
    "- [x] get equity fno list\n",
    "- [x] get lot-size\n",
    "- [x] get market price of options\n",
    "- [x] get volatilities for chains\n",
    "- [x] get all chains with dte for earliest nakeds\n",
    "\n",
    "***\n",
    " - [ ] pack all into symbol objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CELL SHOULD BE IN ALL VSCODE NOTEBOOKS ##\n",
    "\n",
    "MARKET = \"NSE\"\n",
    "\n",
    "# Set the root\n",
    "from from_root import from_root\n",
    "\n",
    "ROOT = from_root()\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add `src` and ROOT to _src.pth in .venv to allow imports in VS Code\n",
    "from sysconfig import get_path\n",
    "\n",
    "if \"src\" not in Path.cwd().parts:\n",
    "    src_path = str(Path(get_path(\"purelib\")) / \"_src.pth\")\n",
    "    with open(src_path, \"w\") as f:\n",
    "        f.write(str(ROOT / \"src\\n\"))\n",
    "        f.write(str(ROOT))\n",
    "        if str(ROOT) not in sys.path:\n",
    "            sys.path.insert(1, str(ROOT))\n",
    "\n",
    "# Start the Jupyter loop\n",
    "from ib_async import util\n",
    "\n",
    "util.startLoop()\n",
    "\n",
    "logger.add(sink=ROOT / \"log\" / \"ztest.log\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "# ---------------\n",
    "\n",
    "import asyncio\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from datetime import date, datetime, time, timedelta, timezone\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from from_root import from_root\n",
    "from ib_async import IB, MarketOrder, Option, Order, util\n",
    "from loguru import logger\n",
    "from pandas import json_normalize\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants, Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONSTANTS ---\n",
    "# -----------------\n",
    "\n",
    "live_port = 3000  # nse\n",
    "paper_port = 3001  # nse paper trade\n",
    "\n",
    "port = PORT = live_port\n",
    "\n",
    "PUTSTDMULT = 1.8\n",
    "CALLSTDMULT = 2.2\n",
    "\n",
    "\n",
    "# Symbol Maps\n",
    "IDX_SYM_HIST_MAP = {\"BANKNIFTY\": \"Nifty Bank\", \"NIFTY\": \"Nifty 50\"}\n",
    "\n",
    "ROOT = from_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN FUNCTION ---\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "def all_early_fnos(fons: Union[List, set], save: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Make all early fnos\"\"\"\n",
    "\n",
    "    timer = Timer(\"Making earliest nakeds\")\n",
    "    timer.start()\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for symbol in fnos:\n",
    "\n",
    "        try:\n",
    "            df_nakeds = make_earliest_naked_opts(symbol)\n",
    "            df_nakeds = df_nakeds[df_nakeds.xPrice > 0]\n",
    "\n",
    "        except AttributeError as e:\n",
    "            logger.error(e)\n",
    "            df_nakeds = None\n",
    "\n",
    "        dfs.append(df_nakeds)\n",
    "\n",
    "        # collect dfs and save\n",
    "        if dfs:\n",
    "            df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "            if save:\n",
    "                pickle_me(df, ROOT / \"data\" / \"earliest_nakeds.pkl\")\n",
    "        else:\n",
    "            df = dfs\n",
    "\n",
    "    timer.stop()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- UTILITIES ---\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "def get_files_from_patterns(pattern: str = \"/*nakeds*\") -> list:\n",
    "    \"\"\"Gets list of files from a folder matching pattern given\"\"\"\n",
    "\n",
    "    ROOT = from_root()\n",
    "\n",
    "    return glob.glob(f\"{ROOT / 'data'}{pattern}\")\n",
    "\n",
    "\n",
    "def nse_ban_list() -> list:\n",
    "    \"\"\"Gets scrips banned today\"\"\"\n",
    "\n",
    "    url = \"https://nsearchives.nseindia.com/content/fo/fo_secban.csv\"\n",
    "    headers = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 \"\n",
    "        \"(KHTML, like Gecko) \"\n",
    "        \"Chrome/80.0.3987.149 Safari/537.36\",\n",
    "        \"accept-language\": \"en,gu;q=0.9,hi;q=0.8\",\n",
    "        \"accept-encoding\": \"gzip, deflate, br\",\n",
    "    }\n",
    "\n",
    "    base_url = \"https://www.nseindia.com\"\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        request = session.get(base_url, headers=headers, timeout=5)\n",
    "        cookies = dict(request.cookies)\n",
    "        response = session.get(url, headers=headers, timeout=5, cookies=cookies)\n",
    "\n",
    "    df = pd.read_csv(io.StringIO(response.text))\n",
    "    ban_list = df.iloc[:, 0].tolist()\n",
    "\n",
    "    return ban_list\n",
    "\n",
    "\n",
    "def live_cache(app_name):\n",
    "    \"\"\"Caches the output for time_out specified. This is done in order to\n",
    "    prevent hitting live quote requests to NSE too frequently. This wrapper\n",
    "    will fetch the quote/live result first time and return the same result for\n",
    "    any calls within 'time_out' seconds.\n",
    "\n",
    "    Logic:\n",
    "        key = concat of args\n",
    "        try:\n",
    "            cached_value = self._cache[key]\n",
    "            if now - self._cache['tstamp'] < time_out\n",
    "                return cached_value['value']\n",
    "        except AttributeError: # _cache attribute has not been created yet\n",
    "            self._cache = {}\n",
    "        finally:\n",
    "            val = fetch-new-value\n",
    "            new_value = {'tstamp': now, 'value': val}\n",
    "            self._cache[key] = new_value\n",
    "            return val\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        \"\"\"Wrapper function which calls the function only after the timeout,\n",
    "        otherwise returns value from the cache.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get key by just concating the list of args and kwargs values and hope\n",
    "        # that it does not break the code :P\n",
    "        inputs = [str(a) for a in args] + [str(kwargs[k]) for k in kwargs]\n",
    "        key = app_name.__name__ + \"-\".join(inputs)\n",
    "        now = datetime.now()\n",
    "        time_out = self.time_out\n",
    "        try:\n",
    "            cache_obj = self._cache[key]\n",
    "            if now - cache_obj[\"timestamp\"] < timedelta(seconds=time_out):\n",
    "                return cache_obj[\"value\"]\n",
    "        except:\n",
    "            self._cache = {}\n",
    "        value = app_name(self, *args, **kwargs)\n",
    "        self._cache[key] = {\"value\": value, \"timestamp\": now}\n",
    "        return value\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def split_dates(days: int = 365, chunks: int = 50) -> list:\n",
    "    \"\"\"splits dates into buckets, based on chunks\"\"\"\n",
    "\n",
    "    end = datetime.today()\n",
    "    periods = int(days / chunks)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    if days < chunks:\n",
    "        date_ranges = [(start, end)]\n",
    "    else:\n",
    "        dates = pd.date_range(start, end, periods).date\n",
    "        date_ranges = list(\n",
    "            zip(pd.Series(dates), pd.Series(dates).shift(-1) + timedelta(days=-1))\n",
    "        )[:-1]\n",
    "\n",
    "    # remove last tuple having period as NaT\n",
    "    if any(pd.isna(e) for element in date_ranges for e in element):\n",
    "        date_ranges = date_ranges[:-1]\n",
    "\n",
    "    return date_ranges\n",
    "\n",
    "\n",
    "def make_date_range_for_stock_history(\n",
    "    symbol: str, days: int = 365, chunks: int = 50\n",
    ") -> list:\n",
    "    \"\"\"Uses `split_dates` to make date range for stock history\"\"\"\n",
    "\n",
    "    date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "    series = \"EQ\"\n",
    "\n",
    "    ranges = [\n",
    "        {\n",
    "            \"symbol\": symbol,\n",
    "            \"from\": start.strftime(\"%d-%m-%Y\"),\n",
    "            \"to\": end.strftime(\"%d-%m-%Y\"),\n",
    "            \"series\": f'[\"{series}\"]',\n",
    "        }\n",
    "        for start, end in date_ranges\n",
    "    ]\n",
    "\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def clean_stock_history(result: list) -> pd.DataFrame:\n",
    "    \"\"\"Cleans output of\"\"\"\n",
    "\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(r.get(\"data\")) for r in result], axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    # ...clean columns\n",
    "\n",
    "    mapping = {\n",
    "        \"CH_SYMBOL\": \"nse_symbol\",\n",
    "        \"TIMESTAMP\": \"date\",\n",
    "        \"CH_OPENING_PRICE\": \"open\",\n",
    "        \"CH_TRADE_HIGH_PRICE\": \"high\",\n",
    "        \"CH_TRADE_LOW_PRICE\": \"low\",\n",
    "        \"CH_CLOSING_PRICE\": \"close\",\n",
    "        \"CH_TOT_TRADED_QTY\": \"qty_traded\",\n",
    "        \"CH_TOT_TRADED_VAL\": \"value_traded\",\n",
    "        \"CH_TOTAL_TRADES\": \"trades\",\n",
    "        \"VWAP\": \"vwap\",\n",
    "        \"updatedAt\": \"extracted_on\",\n",
    "    }\n",
    "\n",
    "    df = df[[col for col in mapping.keys() if col in df.columns]].rename(\n",
    "        columns=mapping\n",
    "    )\n",
    "\n",
    "    # ...convert column datatypes\n",
    "\n",
    "    astype_map = {\n",
    "        **{\n",
    "            k: \"float\"\n",
    "            for k in [\"open\", \"high\", \"low\", \"close\", \"value_traded\", \"trades\", \"vwap\"]\n",
    "        },\n",
    "        **{\"qty_traded\": \"int\"},\n",
    "    }\n",
    "\n",
    "    df = df.astype(astype_map)\n",
    "\n",
    "    # ...change date columns to utc\n",
    "\n",
    "    replace_cols = [\"date\", \"extracted_on\"]\n",
    "    df1 = df[replace_cols].map(lambda x: datetime.fromisoformat(x))\n",
    "    df = df.assign(date=df1.date, extracted_on=df1.extracted_on)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_index_history(results: list) -> pd.DataFrame:\n",
    "    \"\"\"cleans index history and builds it as a dataframe\"\"\"\n",
    "\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(json.loads(r.get(\"d\"))) for r in results], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # clean the df\n",
    "\n",
    "    # ...drop unnecessary columns\n",
    "\n",
    "    df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "\n",
    "    # ...rename\n",
    "    df.columns = [\"nse_symbol\", \"date\", \"open\", \"high\", \"low\", \"close\"]\n",
    "\n",
    "    # ...convert nse_symbol to IB's symbol\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df.nse_symbol.map(\n",
    "                {\"Nifty Bank\": \"BANKNIFTY\", \"Nifty 50\": \"NIFTY50\"}\n",
    "            ).rename(\"symbol\"),\n",
    "            df,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    utc_dates = df.date.apply(lambda x: convert_to_utc_datetime(x, eod=True))\n",
    "\n",
    "    df = df.assign(date=utc_dates)\n",
    "\n",
    "    # .....convert ohlc to numeric\n",
    "    convert_dict = {k: \"float\" for k in [\"open\", \"high\", \"low\", \"close\"]}\n",
    "\n",
    "    df = df.astype(convert_dict)\n",
    "\n",
    "    # .....sort by date\n",
    "    df.sort_values([\"nse_symbol\", \"date\"], inplace=True, ignore_index=True)\n",
    "\n",
    "    # .....add extract_date\n",
    "    now = datetime.now()\n",
    "    utc_now = now.astimezone(timezone.utc)\n",
    "    df = df.assign(extracted_on=utc_now)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_ib_util_df(contracts: Union[list, pd.Series]) -> pd.DataFrame:\n",
    "    \"\"\"Cleans ib_async's util.df to keep only relevant columns\"\"\"\n",
    "\n",
    "    df1 = pd.DataFrame([])  # initialize\n",
    "\n",
    "    if isinstance(contracts, list):\n",
    "        df1 = util.df(contracts)\n",
    "    elif isinstance(contracts, pd.Series):\n",
    "        try:\n",
    "            contract_list = list(contracts)\n",
    "            df1 = util.df(contract_list)  # it could be a series\n",
    "        except (AttributeError, ValueError):\n",
    "            logger.error(f\"cannot clean type: {type(contracts)}\")\n",
    "    else:\n",
    "        logger.error(f\"cannot clean unknowntype: {type(contracts)}\")\n",
    "\n",
    "    if not df1.empty:\n",
    "\n",
    "        df1.rename(\n",
    "            {\"lastTradeDateOrContractMonth\": \"expiry\"}, axis=\"columns\", inplace=True\n",
    "        )\n",
    "\n",
    "        df1 = df1.assign(expiry=pd.to_datetime(df1.expiry))\n",
    "        cols = list(df1.columns[:6])\n",
    "        cols.append(\"multiplier\")\n",
    "        df2 = df1[cols]\n",
    "        df2 = df2.assign(contract=contracts)\n",
    "\n",
    "    else:\n",
    "        df2 = None\n",
    "\n",
    "    return df2\n",
    "\n",
    "\n",
    "def nse2ib(nse_list):\n",
    "    \"\"\"Converts nse to ib friendly symbols\"\"\"\n",
    "\n",
    "    subs = {\"M&M\": \"MM\", \"M&MFIN\": \"MMFIN\", \"L&TFH\": \"LTFH\", \"NIFTY\": \"NIFTY50\"}\n",
    "\n",
    "    list_without_percent_sign = list(map(subs.get, nse_list, nse_list))\n",
    "\n",
    "    # fix length to 9 characters\n",
    "    ib_equity_fnos = [s[:9] for s in list_without_percent_sign]\n",
    "\n",
    "    return ib_equity_fnos\n",
    "\n",
    "\n",
    "def convert_to_utc_datetime(date_string, eod=False):\n",
    "    \"\"\"Converts nse date strings to utc datetimes. If eod is chosen 3:30 PM IST is taken.\"\"\"\n",
    "\n",
    "    # List of possible date formats\n",
    "    date_formats = [\"%d-%b-%Y\", \"%d %b %Y\", \"%Y-%m-%d %H:%M:%S.%f%z\"]\n",
    "\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_string, date_format)\n",
    "\n",
    "            # If the parsed datetime doesn't have timezone info, assume it's UTC\n",
    "            if dt.tzinfo is None:\n",
    "                dt = dt.replace(tzinfo=pytz.UTC)\n",
    "            else:\n",
    "                # If it has timezone info, convert to UTC\n",
    "                dt = dt.astimezone(pytz.UTC)\n",
    "\n",
    "            if eod:\n",
    "                # Set time to 3:30 PM India time for all formats when eod is True\n",
    "                india_time = time(hour=15, minute=30)\n",
    "                india_tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "                dt = india_tz.localize(datetime.combine(dt.date(), india_time))\n",
    "                dt = dt.astimezone(pytz.UTC)\n",
    "            elif dt.time() == time(0, 0):  # If time is midnight (00:00:00)\n",
    "                # Keep it as midnight UTC\n",
    "                dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # If none of the formats work, raise an error\n",
    "    raise ValueError(f\"Unable to parse date string: {date_string}\")\n",
    "\n",
    "\n",
    "def convert_to_numeric(col: pd.Series):\n",
    "    \"\"\"convert to numeric if possible, only for object dtypes\"\"\"\n",
    "\n",
    "    if col.dtype == \"object\":\n",
    "        try:\n",
    "            return pd.to_numeric(col)\n",
    "        except ValueError:\n",
    "            return col\n",
    "    return col\n",
    "\n",
    "\n",
    "def convert_daily_volatility_to_yearly(daily_volatility, days: float = 252):\n",
    "    return daily_volatility * math.sqrt(days)\n",
    "\n",
    "\n",
    "def equity_iv_df(quotes: dict) -> pd.DataFrame:\n",
    "    \"\"\"Build a core df with symbol, undPrice, expiry, strike, volatilities, lot and price.\"\"\"\n",
    "\n",
    "    flat_data = json_normalize(quotes, sep=\"-\")\n",
    "\n",
    "    # get symbol, lot and underlying pricefrom quote\n",
    "\n",
    "    symbol = quotes.get(\"info\").get(\"symbol\")\n",
    "\n",
    "    lot = (\n",
    "        quotes[\"stocks\"][0].get(\"marketDeptOrderBook\").get(\"tradeInfo\").get(\"marketLot\")\n",
    "    )\n",
    "\n",
    "    undPrice = quotes[\"underlyingValue\"]\n",
    "\n",
    "    # build the df\n",
    "    df = pd.DataFrame(flat_data)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"nse_symbol\": symbol,\n",
    "                \"ib_symbol\": symbol,\n",
    "                \"instrument\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"metadata\")\n",
    "                .get(\"instrumentType\"),\n",
    "                \"expiry\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"expiryDate\"),\n",
    "                \"undPrice\": undPrice,\n",
    "                \"safe_strike\": 0,\n",
    "                \"right\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"optionType\")[:1],\n",
    "                \"strike\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"strikePrice\"),\n",
    "                \"dte\": np.nan,\n",
    "                \"hv\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"marketDeptOrderBook\")\n",
    "                .get(\"otherInfo\")\n",
    "                .get(\"annualisedVolatility\"),\n",
    "                \"iv\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"marketDeptOrderBook\")\n",
    "                .get(\"otherInfo\")\n",
    "                .get(\"impliedVolatility\"),\n",
    "                \"lot\": lot,\n",
    "                \"price\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"lastPrice\"),\n",
    "            }\n",
    "            for i in range(len(quotes))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Convert nse_symbol to symbol\n",
    "    df = df.assign(ib_symbol=nse2ib(df.nse_symbol))\n",
    "\n",
    "    # Convert expiry to UTC NSE eod\n",
    "    df = df.assign(\n",
    "        expiry=df.expiry.apply(lambda x: convert_to_utc_datetime(x, eod=True))\n",
    "    )\n",
    "\n",
    "    df = df.assign(dte=get_dte(df.expiry))\n",
    "\n",
    "    # Convert the rest to numeric\n",
    "    df = df.apply(convert_to_numeric)\n",
    "\n",
    "    # Convert to %ge\n",
    "    df.iv = df.iv / 100\n",
    "    df.hv = df.hv / 100\n",
    "\n",
    "    # Change instrument type\n",
    "    instrument_dict = {\n",
    "        \"Stock\": \"STK\",\n",
    "        \"Options\": \"OPT\",\n",
    "        \"Currency\": \"FX\",\n",
    "        \"Index\": \"IDX\",\n",
    "        \"Futures\": \"FUT\",\n",
    "    }\n",
    "\n",
    "    inst = df.instrument.str.split()\n",
    "\n",
    "    s = inst.apply(lambda x: \"\".join(instrument_dict[item] for item in x))\n",
    "\n",
    "    df = df.assign(instrument=s)\n",
    "\n",
    "    df = df[df.instrument.isin([\"IDXOPT\", \"STKOPT\"])]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_closest_strike(df, above=False):\n",
    "    \"\"\"\n",
    "    Finds the row with the strike closest to the undPrice.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    above (bool): If True, find the closest strike above undPrice. If False, find the closest strike below undPrice.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the single row that has the closest strike.\n",
    "    \"\"\"\n",
    "    undPrice = df[\"undPrice\"].iloc[0]  # Get the undPrice from the first row\n",
    "\n",
    "    if above:\n",
    "        # Filter for strikes above undPrice\n",
    "        mask = df[\"strike\"] > undPrice\n",
    "    else:\n",
    "        # Filter for strikes below undPrice\n",
    "        mask = df[\"strike\"] < undPrice\n",
    "\n",
    "    if not mask.any():\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no rows match the criteria\n",
    "\n",
    "    # Calculate the absolute difference between strike and undPrice\n",
    "    diff = np.abs(df.loc[mask, \"strike\"] - undPrice)\n",
    "\n",
    "    # Find the index of the row with the minimum difference\n",
    "    closest_index = diff.idxmin()\n",
    "\n",
    "    # Return the closest row as a DataFrame\n",
    "    return df.loc[[closest_index]]\n",
    "\n",
    "\n",
    "def get_dte(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Gets days to expiry. Expects series of UTC timestamps\"\"\"\n",
    "\n",
    "    now_utc = datetime.now(pytz.UTC)\n",
    "    return (s - now_utc).dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "\n",
    "def fbfillnas(ser: pd.Series) -> pd.Series:\n",
    "    \"\"\"Fills nan in series forwards first and then backwards\"\"\"\n",
    "\n",
    "    s = ser.copy()\n",
    "\n",
    "    # Find the first non-NaN value\n",
    "    first_non_nan = s.dropna().iloc[0]\n",
    "\n",
    "    # Fill first NaN with the first non-NaN value\n",
    "    s.iloc[0] = first_non_nan\n",
    "\n",
    "    # Fill remaining NaN values with the next valid value\n",
    "    s = s.fillna(s.bfill())\n",
    "\n",
    "    # Fill remaining NaN values with the previous valid value\n",
    "    s = s.fillna(s.ffill())\n",
    "\n",
    "    return ser.fillna(s)\n",
    "\n",
    "\n",
    "def get_a_stdev(iv: float, price: float, dte: float) -> float:\n",
    "    \"\"\"Gives 1 Standard Deviation value for annual iv\"\"\"\n",
    "\n",
    "    return iv * price * math.sqrt(dte / 365)\n",
    "\n",
    "\n",
    "def get_prob(sd):\n",
    "    \"\"\"Compute probability of a normal standard deviation\n",
    "\n",
    "    Arg:\n",
    "        (sd) as standard deviation\n",
    "    Returns:\n",
    "        probability as a float\n",
    "\n",
    "    \"\"\"\n",
    "    prob = quad(lambda x: np.exp(-(x**2) / 2) / np.sqrt(2 * np.pi), -sd, sd)[0]\n",
    "    return prob\n",
    "\n",
    "\n",
    "def get_prec(v: float, base: float) -> float:\n",
    "    \"\"\"Gives the precision value\n",
    "\n",
    "    Args:\n",
    "       (v) as value needing precision in float\n",
    "       (base) as the base value e.g. 0.05\n",
    "    Returns:\n",
    "        the precise value\"\"\"\n",
    "\n",
    "    try:\n",
    "        output = round(round((v) / base) * base, -int(math.floor(math.log10(base))))\n",
    "    except Exception:\n",
    "        output = None\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Prettify columns to show based on a dictionary map\n",
    "def pretty_columns(df: pd.DataFrame, col_map: dict) -> list:\n",
    "    \"\"\"prettifies columns based on column map dictionary\"\"\"\n",
    "\n",
    "    cols = [v for _, v in col_map.items() if v in df.columns]\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_ib_margin(contract: Option, order: MarketOrder) -> dict:\n",
    "    \"\"\"Gets margin and commission of a contract\"\"\"\n",
    "\n",
    "    with IB().connect(port=port) as ib:\n",
    "        if contract.conId == 0:  # qualify raw contracts\n",
    "            contract = next(iter(ib.qualifyContracts(contract)))\n",
    "        wif = ib.whatIfOrder(contract, order)\n",
    "\n",
    "    # margin = float(wif.initMarginChange) # initial margin is too high compared to Zerodha, SAMCO\n",
    "    margin = float(wif.maintMarginChange)\n",
    "    comm = min(wif.commission, wif.minCommission, wif.maxCommission)\n",
    "\n",
    "    return {\"contract\": contract, \"margin\": margin, \"comm\": comm}\n",
    "\n",
    "\n",
    "def make_contracts_orders(\n",
    "    df: pd.DataFrame, EXCHANGE: str = \"NSE\", action: str = \"SELL\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Makes df[contract, order] from option df. Used for margin check\"\"\"\n",
    "\n",
    "    df_out = pd.DataFrame(\n",
    "        {\n",
    "            \"contract\": df.apply(\n",
    "                lambda row: Option(\n",
    "                    row.ib_symbol,\n",
    "                    # util.formatIBDatetime(row.expiry.date())[:8],\n",
    "                    util.formatIBDatetime(row.expiry.date()),\n",
    "                    row.strike,\n",
    "                    row.right,\n",
    "                    EXCHANGE,\n",
    "                ),\n",
    "                axis=1,\n",
    "            ),\n",
    "            \"order\": df.apply(\n",
    "                lambda row: MarketOrder(action=action, totalQuantity=row.lot), axis=1\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def get_ib_margin_comms(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Qualified Contracts, Margins and Commissions from an options df\"\"\"\n",
    "\n",
    "    symbol = df.ib_symbol.iloc[0]\n",
    "    df_cos = make_contracts_orders(df)\n",
    "\n",
    "    cts = [d if d.conId == 0 else None for d in df_cos.contract]\n",
    "    with IB().connect(port=port) as ib:\n",
    "        if len(cts) > 40:\n",
    "            ib.qualifyContracts(*tqdm(cts, desc=f\"Qualifying {symbol} options\"))\n",
    "        else:\n",
    "            ib.qualifyContracts(*cts)\n",
    "\n",
    "        df_cos.contract = cts\n",
    "        ib.disconnect()\n",
    "\n",
    "    if len(df_cos) > 1:  # use tqdm.pandas.progress_apply()\n",
    "        tqdm.pandas(desc=f\"Calculating {symbol} margins\")\n",
    "        data = df_cos.progress_apply(\n",
    "            lambda row: get_ib_margin(row.contract, row.order), axis=1\n",
    "        )\n",
    "    else:\n",
    "        data = df_cos.apply(lambda row: get_ib_margin(row.contract, row.order), axis=1)\n",
    "\n",
    "    df_mcom = pd.DataFrame.from_dict(data.to_dict()).T\n",
    "\n",
    "    # replace raw contracts with qualified\n",
    "    df_q = df_cos.join(df_mcom, how=\"outer\", lsuffix=\"_left\").drop(\n",
    "        [\"contract_left\", \"order\"], axis=1\n",
    "    )\n",
    "\n",
    "    # merge margins and commissions\n",
    "    df_opts = df.merge(df_q, left_index=True, right_index=True)\n",
    "\n",
    "    # rename instrument to secType for IB\n",
    "    df_opts = df_opts.assign(\n",
    "        instrument=df_opts.contract.apply(lambda s: s.secType)\n",
    "    ).rename(columns={\"instrument\": \"secType\"}, errors=\"ignore\")\n",
    "\n",
    "    return df_opts\n",
    "\n",
    "\n",
    "def black_scholes(\n",
    "    S: float,  # underlying\n",
    "    K: float,  # strike\n",
    "    T: float,  # years-to-expiry\n",
    "    r: float,  # risk-free rate\n",
    "    sigma: float,  # implied volatility\n",
    "    option_type: str,  # Put or Call right\n",
    ") -> float:\n",
    "    \"\"\"Black-Scholes Option Pricing Model\"\"\"\n",
    "\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "    if option_type == \"C\":\n",
    "        price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    elif option_type == \"P\":\n",
    "        price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid option type. Use 'C' for Call and 'P' for Put.\")\n",
    "\n",
    "    return price\n",
    "\n",
    "\n",
    "def make_earliest_naked_opts(\n",
    "    symbol: str,  # nse_symbol. can be equity or index\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Make target options for nakeds with earliest expiry\"\"\"\n",
    "\n",
    "    # Instantiate nse\n",
    "    nse = NSEfnos()\n",
    "\n",
    "    # Get the basic quote\n",
    "    fno_quote = nse.stock_quote_fno(symbol)\n",
    "\n",
    "    # make the fno df with iv, hv, lot\n",
    "    df_fno = equity_iv_df(fno_quote)\n",
    "\n",
    "    # get margins and commissions from ib\n",
    "    df_mcom = get_ib_margin_comms(df_fno)\n",
    "\n",
    "    # Remove zero IVs\n",
    "    df_mcom = df_mcom[df_mcom.iv > 0]\n",
    "\n",
    "    # Get the risk free rate\n",
    "    rbi = RBI()\n",
    "    risk_free_rate = rbi.repo_rate() / 100\n",
    "\n",
    "    # Compute the expected price from black_scholes\n",
    "    bsPrice = df_mcom.apply(\n",
    "        lambda row: black_scholes(\n",
    "            S=row[\"undPrice\"],\n",
    "            K=row[\"strike\"],\n",
    "            T=row[\"dte\"] / 365,  # Convert days to years\n",
    "            r=risk_free_rate,\n",
    "            sigma=row[\"iv\"],\n",
    "            option_type=row[\"right\"],\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Adjust the expected price precision. Ensure 0.05 as the minimum price.\n",
    "    df = df_mcom.assign(bsPrice=bsPrice.apply(lambda x: get_prec(x, base=0.05)))\n",
    "\n",
    "    # get the safe-strike, based on std multiples\n",
    "    df_sp = pd.concat(\n",
    "        [\n",
    "            df.right,\n",
    "            pd.Series(\n",
    "                df.iv * df.undPrice * (df.dte / 365).apply(math.sqrt), name=\"sdev\"\n",
    "            ),\n",
    "            df.undPrice,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    safe_strike = np.where(\n",
    "        df_sp.right == \"P\",\n",
    "        (df_sp.undPrice - df_sp.sdev * PUTSTDMULT).astype(\"int\"),\n",
    "        (df_sp.undPrice + df_sp.sdev * CALLSTDMULT).astype(\"int\"),\n",
    "    )\n",
    "\n",
    "    df = df.assign(safe_strike=safe_strike)\n",
    "\n",
    "    # derive expected price from safe_strike\n",
    "    df = df.assign(\n",
    "        xPrice=abs(df.safe_strike - df.strike).apply(\n",
    "            lambda x: max(get_prec(x, 0.05), 0.05)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # calculate the return on margin (rom)\n",
    "    df = df.assign(rom=df.xPrice * df.lot / df.margin * 365 / df.dte)\n",
    "\n",
    "    # Sort by likeliest\n",
    "    df_out = df.loc[(df.xPrice / df.price).sort_values().index]\n",
    "\n",
    "    return df_out.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_fnos_from_naked_pickles(maxmargin: int = 300000):\n",
    "    \"\"\"Makes fnos from existing naked pickles\"\"\"\n",
    "\n",
    "    files = get_files_from_patterns(\"/*nakeds*\")\n",
    "\n",
    "    try:\n",
    "        df = pd.concat(\n",
    "            [get_pickle(f) for f in files],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        # Sort by safe_strike: strike ratio to get the safest calls and puts\n",
    "\n",
    "        # ... group calls\n",
    "        gc = (\n",
    "            df[df.right == \"C\"]\n",
    "            .assign(ratio=df.safe_strike / df.strike)\n",
    "            .sort_values(\"ratio\")\n",
    "            .groupby(\"ib_symbol\")\n",
    "        )\n",
    "        df_calls = gc.head(2).sort_values(\n",
    "            [\"ib_symbol\", \"strike\"], ascending=[True, False]\n",
    "        )\n",
    "        dfc = df_calls[df_calls.margin < maxmargin]\n",
    "        dfc = dfc.assign(ratio=dfc.safe_strike / dfc.strike).sort_values(\"ratio\")\n",
    "\n",
    "        # ... group puts\n",
    "        gc = (\n",
    "            df[df.right == \"P\"]\n",
    "            .assign(ratio=df.strike / df.safe_strike)\n",
    "            .sort_values(\"ratio\")\n",
    "            .groupby(\"ib_symbol\")\n",
    "        )\n",
    "        df_puts = gc.head(2).sort_values(\n",
    "            [\"ib_symbol\", \"strike\"], ascending=[True, False]\n",
    "        )\n",
    "        dfp = df_puts[df_puts.margin < maxmargin]\n",
    "        dfp = dfp.assign(ratio=dfp.strike / dfp.safe_strike).sort_values(\"ratio\")\n",
    "\n",
    "        # ... prepare the nakeds to order\n",
    "        df_nakeds = pd.concat([dfc, dfp], axis=0, ignore_index=True)\n",
    "\n",
    "        # ... remove dubious xPrice which are less than option price\n",
    "        df_nakeds = df_nakeds[df_nakeds.xPrice > df_nakeds.price]\n",
    "\n",
    "        df_nakeds = df_nakeds.reset_index(drop=True)\n",
    "\n",
    "    except ValueError:\n",
    "        df_nakeds = None\n",
    "\n",
    "    return df_nakeds\n",
    "\n",
    "\n",
    "# --- PICKLE UTILITIES ----\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "def pickle_me(obj, file_name_with_path: Path):\n",
    "    \"\"\"Pickles objects in a given path\"\"\"\n",
    "\n",
    "    with open(str(file_name_with_path), \"wb\") as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def get_pickle(path: Path, print_msg: bool = True):\n",
    "    \"\"\"Gets pickled object\"\"\"\n",
    "\n",
    "    output = None  # initialize\n",
    "\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            output = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        if print_msg:\n",
    "            logger.error(f\"file not found: {path}\")\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# --- ORDER HANDLING ---\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "def place_orders(ib: IB, cos: Union[tuple, list], blk_size: int = 25) -> List:\n",
    "    \"\"\"!!!CAUTION!!!: This places orders in the system\n",
    "    ---\n",
    "    NOTE: cos could be a single (contract, order)\n",
    "          or a tuple/list of ((c1, o1), (c2, o2)...)\n",
    "          made using tuple(zip(cts, ords))\n",
    "    ---\n",
    "    USAGE:\n",
    "    ---\n",
    "    cos = tuple((c, o) for c, o in zip(contracts, orders))\n",
    "    with IB().connect(port=port) as ib:\n",
    "        ordered = place_orders(ib=ib, cos=cos)\n",
    "    \"\"\"\n",
    "\n",
    "    trades = []\n",
    "\n",
    "    if isinstance(cos, (tuple, list)) and (len(cos) == 2):\n",
    "        c, o = cos\n",
    "        trades.append(ib.placeOrder(c, o))\n",
    "\n",
    "    else:\n",
    "        cobs = {cos[i : i + blk_size] for i in range(0, len(cos), blk_size)}\n",
    "\n",
    "        for b in tqdm(cobs):\n",
    "            for c, o in b:\n",
    "                td = ib.placeOrder(c, o)\n",
    "                trades.append(td)\n",
    "            ib.sleep(0.75)\n",
    "\n",
    "    return trades\n",
    "\n",
    "\n",
    "def get_open_orders(ib, is_active: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Gets open orders - blocking version\"\"\"\n",
    "\n",
    "    ACTIVE_STATUS = \"ApiPending, PendingSubmit, PreSubmitted, Submitted\".split(\",\")\n",
    "\n",
    "    df_openords = OpenOrder().empty()  # Initialize open orders\n",
    "\n",
    "    trades = ib.reqAllOpenOrders()\n",
    "    # trades = ib.trades()\n",
    "    # ib.sleep(1) # time to take in all open orders\n",
    "\n",
    "    if trades:\n",
    "\n",
    "        all_trades_df = (\n",
    "            clean_ib_util_df([t.contract for t in trades])\n",
    "            .join(util.df(t.orderStatus for t in trades))\n",
    "            .join(util.df(t.order for t in trades), lsuffix=\"_\")\n",
    "        )\n",
    "\n",
    "        order = pd.Series([t.order for t in trades], name=\"order\")\n",
    "\n",
    "        all_trades_df = all_trades_df.assign(order=order)\n",
    "\n",
    "        all_trades_df.rename(\n",
    "            {\"lastTradeDateOrContractMonth\": \"expiry\"}, axis=\"columns\", inplace=True\n",
    "        )\n",
    "\n",
    "        # all_trades_df = all_trades_df[all_trades_df.status.isin(ACTIVE_STATUS)]\n",
    "\n",
    "        trades_cols = df_openords.columns\n",
    "\n",
    "        dfo = all_trades_df[trades_cols]\n",
    "\n",
    "        if is_active:\n",
    "            dfo = dfo[dfo.status.isin(ACTIVE_STATUS)]\n",
    "\n",
    "        # dfo = dfo.assign(expiry=pd.to_datetime(dfo.expiry))\n",
    "\n",
    "    return dfo\n",
    "\n",
    "\n",
    "def quick_pf(ib) -> Union[None, pd.DataFrame]:\n",
    "    \"\"\"Gets the portfolio dataframe\"\"\"\n",
    "    pf = ib.portfolio()  # returns an empty [] if there is nothing in the portfolio\n",
    "\n",
    "    if pf != []:\n",
    "        df_pf = util.df(pf)\n",
    "        df_pf = (util.df(list(df_pf.contract)).iloc[:, :6]).join(\n",
    "            df_pf.drop(columns=[\"account\"])\n",
    "        )\n",
    "        df_pf = df_pf.rename(\n",
    "            columns={\n",
    "                \"lastTradeDateOrContractMonth\": \"expiry\",\n",
    "                \"marketPrice\": \"mktPrice\",\n",
    "                \"marketValue\": \"mktVal\",\n",
    "                \"averageCost\": \"avgCost\",\n",
    "                \"unrealizedPNL\": \"unPnL\",\n",
    "                \"realizedPNL\": \"rePnL\",\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        df_pf = Portfolio().empty()\n",
    "\n",
    "    return df_pf\n",
    "\n",
    "\n",
    "def cancel_all():\n",
    "    \"\"\"Cancels all orders\"\"\"\n",
    "\n",
    "    with IB().connect(port=port, clientId=10) as ib:\n",
    "        ib.reqGlobalCancel()\n",
    "\n",
    "\n",
    "# --- TEST BED ---\n",
    "# ----------------\n",
    "\n",
    "\n",
    "def cancel_open_orders(ib) -> pd.DataFrame:\n",
    "    \"\"\"!!!Not working!!! --- CHECK\"\"\"\n",
    "\n",
    "    trades = ib.reqAllOpenOrders()  # To kickstart collection of open orders\n",
    "    ib.sleep(0.3)\n",
    "    trades = ib.trades()  # Get the trades\n",
    "\n",
    "    orders = {\n",
    "        t.order\n",
    "        for t in trades\n",
    "        if t.orderStatus.status == \"Submitted\"\n",
    "        if t.order.action == \"SELL\"\n",
    "    }\n",
    "\n",
    "    # df_open_orders = get_open_orders(ib)\n",
    "    # ords = df_open_orders.order.to_list()\n",
    "\n",
    "    BLK = 25\n",
    "    ords = list(orders)\n",
    "    o_blk = [ords[i : i + BLK] for i in range(0, len(ords), BLK)]\n",
    "\n",
    "    cancels = []\n",
    "\n",
    "    for ob in o_blk:\n",
    "        cancels.append([ib.cancelOrder(o) for o in ob])\n",
    "        ib.sleep(0.3)\n",
    "\n",
    "    return cancels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CLASSES ---\n",
    "# ---------------\n",
    "\n",
    "\n",
    "class NSEfnos:\n",
    "    \"\"\"Class for All NSE FNOS, including Indexes\"\"\"\n",
    "\n",
    "    time_out = 5\n",
    "    base_url = \"https://www.nseindia.com/api\"\n",
    "    page_url = \"https://www.nseindia.com/get-quotes/equity?symbol=LT\"\n",
    "    _routes = {\n",
    "        \"stock_meta\": \"/equity-meta-info\",\n",
    "        \"stock_quote\": \"/quote-equity\",\n",
    "        \"stock_derivative_quote\": \"/quote-derivative\",\n",
    "        \"market_status\": \"/marketStatus\",\n",
    "        \"chart_data\": \"/chart-databyindex\",\n",
    "        \"market_turnover\": \"/market-turnover\",\n",
    "        \"equity_derivative_turnover\": \"/equity-stock\",\n",
    "        \"all_indices\": \"/allIndices\",\n",
    "        \"live_index\": \"/equity-stockIndices\",\n",
    "        \"index_option_chain\": \"/option-chain-indices\",\n",
    "        \"equity_option_chain\": \"/option-chain-equities\",\n",
    "        \"currency_option_chain\": \"/option-chain-currency\",\n",
    "        \"pre_open_market\": \"/market-data-pre-open\",\n",
    "        \"holiday_list\": \"/holiday-master?type=trading\",\n",
    "        \"stock_history\": \"/historical/cm/equity\",  # added by rkv\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.s = requests.Session()\n",
    "        h = {\n",
    "            \"Host\": \"www.nseindia.com\",\n",
    "            \"Referer\": \"https://www.nseindia.com/get-quotes/equity?symbol=SBIN\",\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"pragma\": \"no-cache\",\n",
    "            \"sec-fetch-dest\": \"empty\",\n",
    "            \"sec-fetch-mode\": \"cors\",\n",
    "            \"sec-fetch-site\": \"same-origin\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\",\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "        }\n",
    "        self.s.headers.update(h)\n",
    "        self.s.get(self.page_url)\n",
    "\n",
    "    def get(self, route, payload={}):\n",
    "        url = self.base_url + self._routes[route]\n",
    "        r = self.s.get(url, params=payload)\n",
    "        return r.json()\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote_fno(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_derivative_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def trade_info(self, symbol):\n",
    "        data = {\"symbol\": symbol, \"section\": \"trade_info\"}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def market_status(self):\n",
    "        return self.get(\"market_status\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def chart_data(self, symbol, indices=False):\n",
    "        data = {\"index\": symbol + \"EQN\"}\n",
    "        if indices:\n",
    "            data[\"index\"] = symbol\n",
    "            data[\"indices\"] = \"true\"\n",
    "        return self.get(\"chart_data\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def tick_data(self, symbol, indices=False):\n",
    "        return self.chart_data(symbol, indices)\n",
    "\n",
    "    @live_cache\n",
    "    def market_turnover(self):\n",
    "        return self.get(\"market_turnover\")\n",
    "\n",
    "    @live_cache\n",
    "    def eq_derivative_turnover(self, type=\"allcontracts\"):\n",
    "        data = {\"index\": type}\n",
    "        return self.get(\"equity_derivative_turnover\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def all_indices(self):\n",
    "        return self.get(\"all_indices\")\n",
    "\n",
    "    def live_index(self, symbol=\"NIFTY 50\"):\n",
    "        data = {\"index\": symbol}\n",
    "        return self.get(\"live_index\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def index_option_chain(self, symbol=\"NIFTY\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"index_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def equities_option_chain(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"equity_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def currency_option_chain(self, symbol=\"USDINR\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"currency_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def live_fno(self):\n",
    "        return self.live_index(\"SECURITIES IN F&O\")\n",
    "\n",
    "    @live_cache\n",
    "    def pre_open_market(self, key=\"NIFTY\"):\n",
    "        data = {\"key\": key}\n",
    "        return self.get(\"pre_open_market\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def holiday_list(self):\n",
    "        return self.get(\"holiday_list\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def stock_history(self, symbol, days: int = 365, chunks: int = 50):\n",
    "\n",
    "        date_ranges = make_date_range_for_stock_history(symbol, days, chunks)\n",
    "\n",
    "        result = []\n",
    "        for dr in date_ranges:\n",
    "            result.append(self.get(\"stock_history\", dr))\n",
    "\n",
    "        df = clean_stock_history(result)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def equities(self):\n",
    "        equities_data = nse.live_fno()\n",
    "        equities = {kv.get(\"symbol\") for kv in equities_data.get(\"data\")}\n",
    "        return equities\n",
    "\n",
    "    def indexes(self):\n",
    "        x = \"NIFTY,BANKNIFTY,MIDCPNIFTY,NIFTYNXT50,FINNIFTY\"\n",
    "        return set(x.split(\",\"))\n",
    "\n",
    "\n",
    "class IDXHistories:\n",
    "\n",
    "    time_out = 5\n",
    "    base_url = \"https://niftyindices.com\"\n",
    "    idx_symbols = IDX_SYM_HIST_MAP.values()\n",
    "    url = \"https://niftyindices.com/Backpage.aspx/getHistoricaldatatabletoString\"\n",
    "\n",
    "    # prepare `post` header\n",
    "    post_header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"sec-ch-ua\": '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"',\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"Content-Type\": \"application/json; charset=UTF-8\",\n",
    "        \"Origin\": \"https://niftyindices.com\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Referer\": \"https://niftyindices.com/reports/historical-data\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,hi;q=0.8\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, days: int = 365) -> None:\n",
    "        self.s = requests.Session()\n",
    "\n",
    "        # update session with default headers and get the cookies\n",
    "        init_header = requests.utils.default_headers()\n",
    "        init_header.update(\n",
    "            {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "            }\n",
    "        )\n",
    "        self.s.headers.update(init_header)\n",
    "        c = self.s.get(url=self.url)\n",
    "        self.cookies = c.cookies\n",
    "\n",
    "    def get(self, payload={}):\n",
    "\n",
    "        r = self.s.post(\n",
    "            url=self.url,\n",
    "            headers=self.post_header,\n",
    "            cookies=self.cookies,\n",
    "            data=payload,\n",
    "            timeout=self.time_out,\n",
    "        )\n",
    "\n",
    "        return r.json()\n",
    "\n",
    "    def make_histories(self, days: int = 365, chunks: int = 50):\n",
    "        \"\"\"Makes histories for NIFTY50 and BANKNIFTY, based on number of days provided\"\"\"\n",
    "\n",
    "        date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "        # idx_symbols = [\"Nifty Bank\", \"Nifty 50\"]\n",
    "\n",
    "        # organize the payloads\n",
    "        payloads = [\n",
    "            {\n",
    "                \"cinfo\": str(\n",
    "                    {\n",
    "                        \"name\": idx_symbol,\n",
    "                        \"startDate\": s.strftime(\"%d-%b-%Y\"),\n",
    "                        \"endDate\": e.strftime(\"%d-%b-%Y\"),\n",
    "                        \"indexName\": idx_symbol,\n",
    "                    }\n",
    "                )\n",
    "            }\n",
    "            for s, e in date_ranges\n",
    "            for idx_symbol in self.idx_symbols\n",
    "        ]\n",
    "        # get the raw jsons\n",
    "        results = []\n",
    "\n",
    "        for payload in tqdm(payloads):\n",
    "            r = self.get(payload=json.dumps(payload))\n",
    "            results.append(r)\n",
    "\n",
    "        df = clean_index_history(results)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def rbi_tr_to_json(wrapper):\n",
    "    trs = wrapper.find_all(\"tr\")\n",
    "    op = {}\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if len(tds) >= 2:\n",
    "            key = tds[0].text.strip()\n",
    "            val = tds[1].text.replace(\":\", \"\").replace(\"*\", \"\").replace(\"#\", \"\").strip()\n",
    "\n",
    "            op[key] = val\n",
    "    return op\n",
    "\n",
    "\n",
    "class RBI:\n",
    "    base_url = \"https://www.rbi.org.in/\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.s = requests.Session()\n",
    "\n",
    "    def current_rates(self):\n",
    "        r = self.s.get(self.base_url)\n",
    "\n",
    "        bs = BeautifulSoup(r.text, \"html.parser\")\n",
    "        wrapper = bs.find(\"div\", {\"id\": \"wrapper\"})\n",
    "\n",
    "        return rbi_tr_to_json(wrapper)\n",
    "\n",
    "    def repo_rate(self):\n",
    "\n",
    "        rate = self.current_rates().get(\"Policy Repo Rate\")[:-1]\n",
    "\n",
    "        return float(rate)\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"Timer providing elapsed time\"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"\") -> None:\n",
    "        self.name = name\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start a new timer\"\"\"\n",
    "        if self._start_time is not None:\n",
    "            raise Exception(f\"Timer is running. Use .stop() to stop it\")\n",
    "\n",
    "        now = datetime.now()\n",
    "\n",
    "        print(f'\\n{self.name} started at {now.strftime(\"%d-%b-%Y %H: %M:%S\")}')\n",
    "\n",
    "        self._start_time = datetime.now()\n",
    "\n",
    "    def stop(self) -> None:\n",
    "        if self._start_time is None:\n",
    "            raise Exception(f\"Timer is not running. Use .start() to start it\")\n",
    "\n",
    "        elapsed_time = datetime.now() - self._start_time\n",
    "\n",
    "        # Extract hours, minutes, seconds from the timedelta object\n",
    "        hours = elapsed_time.seconds // 3600\n",
    "        minutes = (elapsed_time.seconds % 3600) // 60\n",
    "        seconds = elapsed_time.seconds % 60\n",
    "\n",
    "        print(f\"\\n...{self.name} took: \" + f\"{hours:02d}:{minutes:02d}:{seconds:02d}\\n\")\n",
    "\n",
    "        self._start_time = None\n",
    "\n",
    "\n",
    "def empty_the_df(df):\n",
    "    \"\"\"Empty the dataclass df\"\"\"\n",
    "    empty_df = pd.DataFrame([df.__dict__]).iloc[0:0]\n",
    "    return empty_df\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OpenOrder:\n",
    "    \"\"\"\n",
    "    Open order template with Dummy data. Use:\\n\n",
    "    `df = OpenOrder().empty()`\n",
    "    \"\"\"\n",
    "\n",
    "    conId: int = 0\n",
    "    symbol: str = \"Dummy\"\n",
    "    secType: str = \"STK\"\n",
    "    expiry: datetime = datetime.now()\n",
    "    strike: float = 0.0\n",
    "    right: str = \"?\"  # Will be 'P' for Put, 'C' for Call\n",
    "    orderId: int = 0\n",
    "    order: Order = None\n",
    "    permId: int = 0\n",
    "    action: str = \"SELL\"  # 'BUY' | 'SELL'\n",
    "    totalQuantity: float = 0.0\n",
    "    lmtPrice: float = 0.0\n",
    "    status: str = None\n",
    "\n",
    "    def empty(self):\n",
    "        return empty_the_df(self)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Portfolio:\n",
    "    \"\"\"\n",
    "    Portfolio template with Dummy data. Use:\\n\n",
    "    `df = OpenOrder().empty()`\n",
    "    \"\"\"\n",
    "\n",
    "    conId: int = 0\n",
    "    symbol: str = \"Dummy\"\n",
    "    secType: str = \"STK\"\n",
    "    expiry: datetime = datetime.now()\n",
    "    strike: float = 0.0\n",
    "    right: str = \"?\"  # Will be 'P' for Put, 'C' for Call\n",
    "    position: float = 0.0\n",
    "    mktPrice: float = 0.0\n",
    "    mktVal: float = 0.0\n",
    "    avgCost: float = 0.0\n",
    "    unPnL: float = 0.0\n",
    "    rePnL: float = 0.0\n",
    "\n",
    "    def empty(self):\n",
    "        return empty_the_df(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FnO class\n",
    "nse = NSEfnos()\n",
    "\n",
    "# get executed symbols from pickles\n",
    "files = get_files_from_patterns(\"/*nakeds*\")\n",
    "symbols_list = [get_pickle(ROOT / \"data\" / file).nse_symbol.to_list() for file in files]\n",
    "executed = set(chain.from_iterable(symbols_list))\n",
    "\n",
    "# get open order symbols\n",
    "with IB().connect(port=port, clientId=10) as ib:\n",
    "\n",
    "    trades = ib.reqAllOpenOrders()\n",
    "    try:\n",
    "        df_openords = get_open_orders(ib)\n",
    "        open_orders = set(df_openords.symbol.to_list())\n",
    "    except UnboundLocalError as e:\n",
    "        logger.info(f\"No open orders found in Big Test. {e}\")\n",
    "        open_orders = set() #empty \n",
    "\n",
    "# build the fnos list\n",
    "fnos = ((set([\"BANKNIFTY\", \"NIFTY\"]) | nse.equities()) - executed) - open_orders\n",
    "fnos = list(fnos - set(nse_ban_list()))\n",
    "fnos.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the earliest naked options\n",
    "\n",
    "if fnos:\n",
    "    df_nakeds = all_early_fnos(fnos, save=True)\n",
    "\n",
    "    out = {\n",
    "        \"current_#fnos\": len(fnos),\n",
    "        \"unique_symbols\": len(df_nakeds.ib_symbol.unique()),\n",
    "        \"# of orders\": len(df_nakeds),\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nakeds = get_fnos_from_naked_pickles()\n",
    "print(f\"\\n{out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nakeds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing the orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLACE THE ORDERS !!!\n",
    "\n",
    "from ib_async import LimitOrder\n",
    "\n",
    "# df_nakeds = all_early_fnos(fnos, save=False)\n",
    "\n",
    "contracts = df_nakeds.contract.to_list()\n",
    "orders = [\n",
    "    LimitOrder(action=\"SELL\", totalQuantity=abs(int(q)), lmtPrice=p)\n",
    "    for q, p in zip(df_nakeds.lot, df_nakeds.xPrice)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cos = tuple((c, o) for c, o in zip(contracts, orders))\n",
    "\n",
    "with IB().connect(port=3000) as ib:\n",
    "    ordered = place_orders(ib=ib, cos=cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{datetime.now().strftime('%Y%m%d_%Hh%Mm%Ss')}_orders.pkl\"\n",
    "pickle_me(ordered, str(ROOT / \"data\" / \"zArchive\" / filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with IB().connect(port=port, clientId=10) as ib:\n",
    "    df_openords = get_open_orders(ib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be continued ...\n",
    "- Make next period (week: NIFTY, month: for rest) naked options\n",
    "- Compute overbought and oversold from history to test df_nakeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Price (Stock Only! NOT FOR INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"RELIANCE\"\n",
    "q = nse.stock_quote(symbol)\n",
    "\n",
    "stock_price = q.get(\"priceInfo\").get(\"lastPrice\")\n",
    "\n",
    "stock_price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
