{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get one symbol nakeds for `NSE`\n",
    "***\n",
    "\n",
    "# !!! `REMEMBER TO REMOVE PREVIOUS EARLIEST NAKEDS PICKLES` !!!\n",
    "\n",
    "THIS NEEDS TO CHANGE TO `EARLIEST NAKEDS` !!!\n",
    "\n",
    "- [x] get equity fno list\n",
    "- [x] get lot-size\n",
    "- [x] get market price of options\n",
    "- [x] get volatilities for chains\n",
    "- [x] get all chains with dte for earliest nakeds\n",
    "\n",
    "***\n",
    " - [ ] pack all into symbol objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:24.540831Z",
     "iopub.status.busy": "2024-07-28T15:13:24.540831Z",
     "iopub.status.idle": "2024-07-28T15:13:25.677982Z",
     "shell.execute_reply": "2024-07-28T15:13:25.677982Z",
     "shell.execute_reply.started": "2024-07-28T15:13:24.540831Z"
    }
   },
   "outputs": [],
   "source": [
    "## THIS CELL SHOULD BE IN ALL VSCODE NOTEBOOKS ##\n",
    "\n",
    "MARKET = \"NSE\"\n",
    "\n",
    "# Set the root\n",
    "from from_root import from_root\n",
    "\n",
    "ROOT = from_root()\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add `src` and ROOT to _src.pth in .venv to allow imports in VS Code\n",
    "from sysconfig import get_path\n",
    "\n",
    "if \"src\" not in Path.cwd().parts:\n",
    "    src_path = str(Path(get_path(\"purelib\")) / \"_src.pth\")\n",
    "    with open(src_path, \"w\") as f:\n",
    "        f.write(str(ROOT / \"src\\n\"))\n",
    "        f.write(str(ROOT))\n",
    "        if str(ROOT) not in sys.path:\n",
    "            sys.path.insert(1, str(ROOT))\n",
    "\n",
    "# Start the Jupyter loop\n",
    "from ib_async import util\n",
    "\n",
    "util.startLoop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:25.677982Z",
     "iopub.status.busy": "2024-07-28T15:13:25.677982Z",
     "iopub.status.idle": "2024-07-28T15:13:27.597339Z",
     "shell.execute_reply": "2024-07-28T15:13:27.597339Z",
     "shell.execute_reply.started": "2024-07-28T15:13:25.677982Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "# ---------------\n",
    "\n",
    "import asyncio\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import logging  # for ib_async log redirection\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from datetime import date, datetime, time, timedelta, timezone\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "import yaml\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from from_root import from_root\n",
    "from ib_async import IB, LimitOrder, MarketOrder, Option, Order, util\n",
    "from loguru import logger\n",
    "from pandas import json_normalize\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools (Utilties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.599344Z",
     "iopub.status.busy": "2024-07-28T15:13:27.599344Z",
     "iopub.status.idle": "2024-07-28T15:13:27.642648Z",
     "shell.execute_reply": "2024-07-28T15:13:27.641634Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.599344Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- TOOLS ---\n",
    "# -------------\n",
    "\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Loads configuration from .env and config.yml files.\"\"\"\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv()\n",
    "\n",
    "    # Load config from YAML file\n",
    "\n",
    "    ROOT = from_root()\n",
    "    with open(ROOT / \"config\" / \"config.yml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    # Merge environment variables with config\n",
    "    for key, value in os.environ.items():\n",
    "        if key in config:\n",
    "            config[key] = value\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def delete_files(file_paths):\n",
    "    \"\"\"Deletes a list or set of files.\n",
    "\n",
    "    Args:\n",
    "      file_paths: A list or set of file paths as strings.\n",
    "    \"\"\"\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error deleting file: {file_path}, {e}\")\n",
    "\n",
    "\n",
    "def get_pickle_suffix(pattern: str = \"/*nakeds*\"):\n",
    "    \"\"\"Checks pickle file name suffix and gets the next digit\"\"\"\n",
    "\n",
    "    def extract_suffix(file):\n",
    "        try:\n",
    "            return int(file[:-4][-1])\n",
    "        except ValueError:\n",
    "            return 0\n",
    "\n",
    "    files = get_files_from_patterns(pattern)\n",
    "    suffixes = [extract_suffix(file) for file in files]\n",
    "    return max(suffixes) + 1 if suffixes else 1\n",
    "\n",
    "\n",
    "def yes_or_no(question, default=\"n\") -> bool:\n",
    "  \"\"\"Asks a yes or no question with a default answer.\n",
    "\n",
    "  Args:\n",
    "    question: The question to ask.\n",
    "    default: The default answer if the user presses Enter.\n",
    "\n",
    "  Returns:\n",
    "    True if the user answered yes, False otherwise.\n",
    "  \"\"\"\n",
    "\n",
    "  while True:\n",
    "    answer = input(question + f\" (y/n): \").lower().strip()\n",
    "    if not answer:\n",
    "      return default == \"y\"\n",
    "    if answer in (\"y\", \"yes\"):\n",
    "      return True\n",
    "    elif answer in (\"n\", \"no\"):\n",
    "      return False\n",
    "    else:\n",
    "      print(\"Please answer yes or no.\")\n",
    "\n",
    "\n",
    "def remove_raw_nakeds(save: bool=True):\n",
    "\n",
    "    # consolidate and pickle\n",
    "    files = get_files_from_patterns(pattern=\"*nakeds*\")\n",
    "\n",
    "    if files:\n",
    "        df_nakeds = pd.concat([get_pickle(f) for f in files], ignore_index=True)\n",
    "\n",
    "        # save a df_nakeds for rough use\n",
    "        if save:\n",
    "            pickle_me(df_nakeds, ROOT / \"data\" / \"df_nakeds.pkl\")\n",
    "\n",
    "            # historize\n",
    "            filename = f\"{datetime.now().strftime('%Y%m%d_%I_%M_%p')}_naked_orders.pkl\"\n",
    "            pickle_me(df_nakeds, str(ROOT / \"data\" / \"xn_history\" / str(filename)))\n",
    "\n",
    "        # delete consolidated files\n",
    "        delete_files(files)\n",
    "        logger.info(f\"Deleted files {files}\")\n",
    "\n",
    "\n",
    "def get_files_from_patterns(log_path = None, pattern: str = \"*nakeds*\") -> list:\n",
    "    \"\"\"Gets list of files of matching pattern from a folder path \"\"\"\n",
    "\n",
    "    ROOT = from_root()\n",
    "\n",
    "    if log_path is None: # Defaults to raw data folder\n",
    "        log_path = ROOT / 'data' / 'raw'\n",
    "\n",
    "    result = glob.glob(str(log_path / pattern))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def split_dates(days: int = 365, chunks: int = 50) -> list:\n",
    "    \"\"\"splits dates into buckets, based on chunks\"\"\"\n",
    "\n",
    "    end = datetime.today()\n",
    "    periods = int(days / chunks)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    if days < chunks:\n",
    "        date_ranges = [(start, end)]\n",
    "    else:\n",
    "        dates = pd.date_range(start, end, periods).date\n",
    "        date_ranges = list(\n",
    "            zip(pd.Series(dates), pd.Series(dates).shift(-1) + timedelta(days=-1))\n",
    "        )[:-1]\n",
    "\n",
    "    # remove last tuple having period as NaT\n",
    "    if any(pd.isna(e) for element in date_ranges for e in element):\n",
    "        date_ranges = date_ranges[:-1]\n",
    "\n",
    "    return date_ranges\n",
    "\n",
    "\n",
    "def clean_ib_util_df(contracts: Union[list, pd.Series]) -> pd.DataFrame:\n",
    "    \"\"\"Cleans ib_async's util.df to keep only relevant columns\"\"\"\n",
    "\n",
    "    df1 = pd.DataFrame([])  # initialize\n",
    "\n",
    "    if isinstance(contracts, list):\n",
    "        df1 = util.df(contracts)\n",
    "    elif isinstance(contracts, pd.Series):\n",
    "        try:\n",
    "            contract_list = list(contracts)\n",
    "            df1 = util.df(contract_list)  # it could be a series\n",
    "        except (AttributeError, ValueError):\n",
    "            logger.error(f\"cannot clean type: {type(contracts)}\")\n",
    "    else:\n",
    "        logger.error(f\"cannot clean unknowntype: {type(contracts)}\")\n",
    "\n",
    "    if not df1.empty:\n",
    "\n",
    "        df1.rename(\n",
    "            {\"lastTradeDateOrContractMonth\": \"expiry\"}, axis=\"columns\", inplace=True\n",
    "        )\n",
    "\n",
    "        df1 = df1.assign(expiry=pd.to_datetime(df1.expiry))\n",
    "        cols = list(df1.columns[:6])\n",
    "        cols.append(\"multiplier\")\n",
    "        df2 = df1[cols]\n",
    "        df2 = df2.assign(contract=contracts)\n",
    "\n",
    "    else:\n",
    "        df2 = None\n",
    "\n",
    "    return df2\n",
    "\n",
    "\n",
    "def convert_to_utc_datetime(date_string, eod=False):\n",
    "    \"\"\"Converts nse date strings to utc datetimes. If eod is chosen 3:30 PM IST is taken.\"\"\"\n",
    "\n",
    "    # List of possible date formats\n",
    "    date_formats = [\"%d-%b-%Y\", \"%d %b %Y\", \"%Y-%m-%d %H:%M:%S.%f%z\"]\n",
    "\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_string, date_format)\n",
    "\n",
    "            # If the parsed datetime doesn't have timezone info, assume it's UTC\n",
    "            if dt.tzinfo is None:\n",
    "                dt = dt.replace(tzinfo=pytz.UTC)\n",
    "            else:\n",
    "                # If it has timezone info, convert to UTC\n",
    "                dt = dt.astimezone(pytz.UTC)\n",
    "\n",
    "            if eod:\n",
    "                # Set time to 3:30 PM India time for all formats when eod is True\n",
    "                india_time = time(hour=15, minute=30)\n",
    "                india_tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "                dt = india_tz.localize(datetime.combine(dt.date(), india_time))\n",
    "                dt = dt.astimezone(pytz.UTC)\n",
    "            elif dt.time() == time(0, 0):  # If time is midnight (00:00:00)\n",
    "                # Keep it as midnight UTC\n",
    "                dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # If none of the formats work, raise an error\n",
    "    raise ValueError(f\"Unable to parse date string: {date_string}\")\n",
    "\n",
    "\n",
    "def convert_to_numeric(col: pd.Series):\n",
    "    \"\"\"convert to numeric if possible, only for object dtypes\"\"\"\n",
    "\n",
    "    if col.dtype == \"object\":\n",
    "        try:\n",
    "            return pd.to_numeric(col)\n",
    "        except ValueError:\n",
    "            return col\n",
    "    return col\n",
    "\n",
    "\n",
    "def convert_daily_volatility_to_yearly(daily_volatility, days: float = 252):\n",
    "    return daily_volatility * math.sqrt(days)\n",
    "\n",
    "\n",
    "def find_closest_strike(df, above=False):\n",
    "    \"\"\"\n",
    "    Finds the row with the strike closest to the undPrice.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    above (bool): If True, find the closest strike above undPrice. If False, find the closest strike below undPrice.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the single row that has the closest strike.\n",
    "    \"\"\"\n",
    "    undPrice = df[\"undPrice\"].iloc[0]  # Get the undPrice from the first row\n",
    "\n",
    "    if above:\n",
    "        # Filter for strikes above undPrice\n",
    "        mask = df[\"strike\"] > undPrice\n",
    "    else:\n",
    "        # Filter for strikes below undPrice\n",
    "        mask = df[\"strike\"] < undPrice\n",
    "\n",
    "    if not mask.any():\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no rows match the criteria\n",
    "\n",
    "    # Calculate the absolute difference between strike and undPrice\n",
    "    diff = np.abs(df.loc[mask, \"strike\"] - undPrice)\n",
    "\n",
    "    # Find the index of the row with the minimum difference\n",
    "    closest_index = diff.idxmin()\n",
    "\n",
    "    # Return the closest row as a DataFrame\n",
    "    return df.loc[[closest_index]]\n",
    "\n",
    "\n",
    "def get_dte(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Gets days to expiry. Expects series of UTC timestamps\"\"\"\n",
    "\n",
    "    now_utc = datetime.now(pytz.UTC)\n",
    "    return (s - now_utc).dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "\n",
    "def fbfillnas(ser: pd.Series) -> pd.Series:\n",
    "    \"\"\"Fills nan in series forwards first and then backwards\"\"\"\n",
    "\n",
    "    s = ser.copy()\n",
    "\n",
    "    # Find the first non-NaN value\n",
    "    first_non_nan = s.dropna().iloc[0]\n",
    "\n",
    "    # Fill first NaN with the first non-NaN value\n",
    "    s.iloc[0] = first_non_nan\n",
    "\n",
    "    # Fill remaining NaN values with the next valid value\n",
    "    s = s.fillna(s.bfill())\n",
    "\n",
    "    # Fill remaining NaN values with the previous valid value\n",
    "    s = s.fillna(s.ffill())\n",
    "\n",
    "    return ser.fillna(s)\n",
    "\n",
    "\n",
    "def get_a_stdev(iv: float, price: float, dte: float) -> float:\n",
    "    \"\"\"Gives 1 Standard Deviation value for annual iv\"\"\"\n",
    "\n",
    "    return iv * price * math.sqrt(dte / 365)\n",
    "\n",
    "\n",
    "def get_prob(sd):\n",
    "    \"\"\"Compute probability of a normal standard deviation\n",
    "\n",
    "    Arg:\n",
    "        (sd) as standard deviation\n",
    "    Returns:\n",
    "        probability as a float\n",
    "\n",
    "    \"\"\"\n",
    "    prob = quad(lambda x: np.exp(-(x**2) / 2) / np.sqrt(2 * np.pi), -sd, sd)[0]\n",
    "    return prob\n",
    "\n",
    "\n",
    "def get_prec(v: float, base: float) -> float:\n",
    "    \"\"\"Gives the precision value\n",
    "\n",
    "    Args:\n",
    "       (v) as value needing precision in float\n",
    "       (base) as the base value e.g. 0.05\n",
    "    Returns:\n",
    "        the precise value\"\"\"\n",
    "\n",
    "    try:\n",
    "        output = round(round((v) / base) * base, -int(math.floor(math.log10(base))))\n",
    "    except Exception:\n",
    "        output = None\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_contracts_orders(\n",
    "    df: pd.DataFrame, EXCHANGE: str = \"NSE\", action: str = \"SELL\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Makes df[contract, order] from option df. Used for margin check\"\"\"\n",
    "\n",
    "    df_out = pd.DataFrame(\n",
    "        {\n",
    "            \"contract\": df.apply(\n",
    "                lambda row: Option(\n",
    "                    row.ib_symbol,\n",
    "                    # util.formatIBDatetime(row.expiry.date())[:8],\n",
    "                    util.formatIBDatetime(row.expiry.date()),\n",
    "                    row.strike,\n",
    "                    row.right,\n",
    "                    EXCHANGE,\n",
    "                ),\n",
    "                axis=1,\n",
    "            ),\n",
    "            \"order\": df.apply(\n",
    "                lambda row: MarketOrder(action=action, totalQuantity=row.lot), axis=1\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def black_scholes(\n",
    "    S: float,  # underlying\n",
    "    K: float,  # strike\n",
    "    T: float,  # years-to-expiry\n",
    "    r: float,  # risk-free rate\n",
    "    sigma: float,  # implied volatility\n",
    "    option_type: str,  # Put or Call right\n",
    ") -> float:\n",
    "    \"\"\"Black-Scholes Option Pricing Model\"\"\"\n",
    "\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "    if option_type == \"C\":\n",
    "        price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    elif option_type == \"P\":\n",
    "        price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid option type. Use 'C' for Call and 'P' for Put.\")\n",
    "\n",
    "    return price\n",
    "\n",
    "\n",
    "def arrange_df_columns(df: pd.DataFrame, col_map: str) -> list:\n",
    "    \"\"\"\n",
    "    Arranges columns based on col_map given\n",
    "    \"\"\"\n",
    "\n",
    "    cols = []\n",
    "\n",
    "    if isinstance(col_map, str):\n",
    "        v = re.split(r\"[,\\t\\s]+\", col_map)\n",
    "        cols = [s for s in v if s in df.columns]\n",
    "\n",
    "    return cols\n",
    "\n",
    "\n",
    "def arrange_orders(df: pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Arranges orders to get the best ROM and filters out excessive margins\n",
    "    \n",
    "    Usage:\n",
    "      arrange_orders(df, \n",
    "                   maxmargin=MAXMARGINPERORDER, \n",
    "                   how_many=2,\n",
    "                   puts_only=True)\"\"\"\n",
    "\n",
    "    MARKET = df.contract.iloc[0].exchange\n",
    "\n",
    "    # Takes maxmargin if it is provided. Else defaults it to 5,000 for SNP\n",
    "    maxmargin = kwargs.get('maxmargin', 5000)\n",
    "    how_many = kwargs.get('how_many', 2)\n",
    "    puts_only = kwargs.get('puts_only', False)\n",
    "\n",
    "    # files = get_files_from_patterns(\"/*nakeds*\")\n",
    "\n",
    "\n",
    "    # Sort by safe_strike: strike ratio to get the safest calls and puts\n",
    "\n",
    "    # ... group calls\n",
    "\n",
    "    if not puts_only:\n",
    "        gc = (\n",
    "            df[df.right == \"C\"]\n",
    "            .assign(ratio=df.safe_strike / df.strike)\n",
    "            .sort_values(\"ratio\")\n",
    "            .groupby(\"ib_symbol\")\n",
    "        )\n",
    "        df_calls = gc.head(how_many).sort_values(\n",
    "            [\"ib_symbol\", \"strike\"], ascending=[True, False]\n",
    "        )\n",
    "        dfc = df_calls[df_calls.margin < maxmargin]\n",
    "        dfc = dfc.assign(ratio=dfc.safe_strike / dfc.strike).sort_values(\"ratio\")\n",
    "    else:\n",
    "        dfc = pd.DataFrame([])\n",
    "\n",
    "    # ... group puts\n",
    "    gc = (\n",
    "        df[df.right == \"P\"]\n",
    "        .assign(ratio=df.strike / df.safe_strike)\n",
    "        .sort_values(\"ratio\")\n",
    "        .groupby(\"ib_symbol\")\n",
    "    )\n",
    "    df_puts = gc.head(how_many).sort_values(\n",
    "        [\"ib_symbol\", \"strike\"], ascending=[True, False]\n",
    "    )\n",
    "    dfp = df_puts[df_puts.margin < maxmargin]\n",
    "    dfp = dfp.assign(ratio=dfp.strike / dfp.safe_strike).sort_values(\"ratio\")\n",
    "\n",
    "    # ... prepare the nakeds to order\n",
    "    df_nakeds = pd.concat([dfc, dfp], axis=0, ignore_index=True)\n",
    "\n",
    "    # ... remove dubious xPrice which are less than option price\n",
    "    df_nakeds = df_nakeds[df_nakeds.xPrice > df_nakeds.price]\n",
    "\n",
    "    df_nakeds = df_nakeds.reset_index(drop=True)\n",
    "\n",
    "    # Sort the DataFrame by 'xPrice/price' in ascending order\n",
    "    df_nakeds = df_nakeds.loc[\n",
    "        df_nakeds[\"xPrice\"].\n",
    "            div(df_nakeds[\"price\"]).\n",
    "            sort_values().index\n",
    "    ]\n",
    "\n",
    "    return df_nakeds\n",
    "\n",
    "\n",
    "# --- PICKLE TOOLS ----\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "def pickle_me(obj, file_name_with_path: Path):\n",
    "    \"\"\"Pickles objects in a given path\"\"\"\n",
    "\n",
    "    with open(str(file_name_with_path), \"wb\") as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def get_pickle(path: Path, print_msg: bool = True):\n",
    "    \"\"\"Gets pickled object\"\"\"\n",
    "\n",
    "    output = None  # initialize\n",
    "\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            output = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        if print_msg:\n",
    "            logger.error(f\"file not found: {path}\")\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IB functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:16:16.725749Z",
     "iopub.status.busy": "2024-07-28T15:16:16.725749Z",
     "iopub.status.idle": "2024-07-28T15:16:16.769734Z",
     "shell.execute_reply": "2024-07-28T15:16:16.767721Z",
     "shell.execute_reply.started": "2024-07-28T15:16:16.725749Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- IB FUNCTIONS ----\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "def get_ib_margin(contract: Option, order: MarketOrder, port: int) -> dict:\n",
    "    \"\"\"Gets margin and commission of a contract\"\"\"\n",
    "\n",
    "    with IB().connect(port=port) as ib:\n",
    "        if contract.conId == 0:  # qualify raw contracts\n",
    "            contract = next(iter(ib.qualifyContracts(contract)))\n",
    "        wif = ib.whatIfOrder(contract, order)\n",
    "\n",
    "    # margin = float(wif.initMarginChange) # initial margin is too high compared to Zerodha, SAMCO\n",
    "    margin = float(wif.maintMarginChange)\n",
    "    comm = min(float(wif.commission), float(wif.minCommission), float(wif.maxCommission))\n",
    "    if comm > 1e7:\n",
    "        comm = np.nan\n",
    "\n",
    "    return {\"contract\": contract, \"margin\": margin, \"comm\": comm}\n",
    "\n",
    "\n",
    "def get_ib_margin_comms(df: pd.DataFrame, port: int) -> pd.DataFrame:\n",
    "    \"\"\"Qualified Contracts, Margins and Commissions from an options df\"\"\"\n",
    "\n",
    "    symbol = df.ib_symbol.iloc[0]\n",
    "    df_cos = make_contracts_orders(df)\n",
    "\n",
    "    cts = [d if d.conId == 0 else None for d in df_cos.contract]\n",
    "    with IB().connect(port=port) as ib:\n",
    "        if len(cts) > 40:\n",
    "            ib.qualifyContracts(*tqdm(cts, desc=f\"Qualifying {symbol} options\"))\n",
    "        else:\n",
    "            ib.qualifyContracts(*cts)\n",
    "\n",
    "        df_cos.contract = cts\n",
    "        ib.disconnect()\n",
    "\n",
    "    if len(df_cos) > 1:  # use tqdm.pandas.progress_apply()\n",
    "        tqdm.pandas(desc=f\"Calculating {symbol} margins\")\n",
    "        data = df_cos.progress_apply(\n",
    "            lambda row: get_ib_margin(row.contract, row.order, port=port), axis=1\n",
    "        )\n",
    "    else:\n",
    "        data = df_cos.apply(lambda row: get_ib_margin(row.contract, row.order, port=port), axis=1)\n",
    "\n",
    "    df_mcom = pd.DataFrame.from_dict(data.to_dict()).T\n",
    "\n",
    "    # replace raw contracts with qualified\n",
    "    df_q = df_cos.join(df_mcom, how=\"outer\", lsuffix=\"_left\").drop(\n",
    "        [\"contract_left\", \"order\"], axis=1\n",
    "    )\n",
    "\n",
    "    # merge margins and commissions\n",
    "    df_opts = df.merge(df_q, left_index=True, right_index=True, suffixes=('_left', ''))\n",
    "    df_opts = df_opts.drop(columns='contract_left', errors='ignore')\n",
    "\n",
    "    # determine the secType for IB\n",
    "    df_opts = df_opts.assign(secType=df_opts.contract.apply(lambda s: s.secType))\n",
    "\n",
    "    return df_opts\n",
    "\n",
    "\n",
    "# --- ORDER HANDLING ---\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "def place_orders(ib: IB, cos: Union[tuple, list], blk_size: int = 25) -> List:\n",
    "    \"\"\"!!!CAUTION!!!: This places orders in the system\n",
    "    ---\n",
    "    NOTE: cos could be a single (contract, order)\n",
    "          or a tuple/list of ((c1, o1), (c2, o2)...)\n",
    "          made using tuple(zip(cts, ords))\n",
    "    ---\n",
    "    USAGE:\n",
    "    ---\n",
    "    cos = tuple((c, o) for c, o in zip(contracts, orders))\n",
    "    with IB().connect(port=port) as ib:\n",
    "        ordered = place_orders(ib=ib, cos=cos)\n",
    "    \"\"\"\n",
    "\n",
    "    trades = []\n",
    "\n",
    "    if isinstance(cos, (tuple, list)) and (len(cos) == 2):\n",
    "        c, o = cos\n",
    "        trades.append(ib.placeOrder(c, o))\n",
    "\n",
    "    else:\n",
    "        cobs = {cos[i : i + blk_size] for i in range(0, len(cos), blk_size)}\n",
    "\n",
    "        for b in tqdm(cobs):\n",
    "            for c, o in b:\n",
    "                td = ib.placeOrder(c, o)\n",
    "                trades.append(td)\n",
    "            ib.sleep(0.75)\n",
    "\n",
    "    return trades\n",
    "\n",
    "\n",
    "def get_open_orders(ib, is_active: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Gets open orders - blocking version\"\"\"\n",
    "\n",
    "    ACTIVE_STATUS = \"ApiPending, PendingSubmit, PreSubmitted, Submitted\".split(\",\")\n",
    "\n",
    "    df_openords = OpenOrder().empty()  # Initialize open orders\n",
    "\n",
    "    trades = ib.reqAllOpenOrders()\n",
    "    # trades = ib.trades()\n",
    "    # ib.sleep(1) # time to take in all open orders\n",
    "\n",
    "    if trades:\n",
    "\n",
    "        all_trades_df = (\n",
    "            clean_ib_util_df([t.contract for t in trades])\n",
    "            .join(util.df(t.orderStatus for t in trades))\n",
    "            .join(util.df(t.order for t in trades), lsuffix=\"_\")\n",
    "        )\n",
    "\n",
    "        order = pd.Series([t.order for t in trades], name=\"order\")\n",
    "\n",
    "        all_trades_df = all_trades_df.assign(order=order)\n",
    "\n",
    "        all_trades_df.rename(\n",
    "            {\"lastTradeDateOrContractMonth\": \"expiry\"}, axis=\"columns\", inplace=True\n",
    "        )\n",
    "\n",
    "        # all_trades_df = all_trades_df[all_trades_df.status.isin(ACTIVE_STATUS)]\n",
    "\n",
    "        trades_cols = df_openords.columns\n",
    "\n",
    "        dfo = all_trades_df[trades_cols]\n",
    "\n",
    "        if is_active:\n",
    "            dfo = dfo[dfo.status.isin(ACTIVE_STATUS)]\n",
    "\n",
    "        # dfo = dfo.assign(expiry=pd.to_datetime(dfo.expiry))\n",
    "\n",
    "    return dfo\n",
    "\n",
    "\n",
    "def quick_pf(ib) -> Union[None, pd.DataFrame]:\n",
    "    \"\"\"Gets the portfolio dataframe\"\"\"\n",
    "    pf = ib.portfolio()  # returns an empty [] if there is nothing in the portfolio\n",
    "\n",
    "    if pf != []:\n",
    "        df_pf = util.df(pf)\n",
    "        df_pf = (util.df(list(df_pf.contract)).iloc[:, :6]).join(\n",
    "            df_pf.drop(columns=[\"account\"])\n",
    "        )\n",
    "        df_pf = df_pf.rename(\n",
    "            columns={\n",
    "                \"lastTradeDateOrContractMonth\": \"expiry\",\n",
    "                \"marketPrice\": \"mktPrice\",\n",
    "                \"marketValue\": \"mktVal\",\n",
    "                \"averageCost\": \"avgCost\",\n",
    "                \"unrealizedPNL\": \"unPnL\",\n",
    "                \"realizedPNL\": \"rePnL\",\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        df_pf = Portfolio().empty()\n",
    "\n",
    "    return df_pf\n",
    "\n",
    "\n",
    "def cancel_all(port: int):\n",
    "    \"\"\"Cancels all orders\"\"\"\n",
    "\n",
    "    with IB().connect(port=port, clientId=10) as ib:\n",
    "        ib.reqGlobalCancel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set logger for ib_async logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.663795Z",
     "iopub.status.busy": "2024-07-28T15:13:27.663795Z",
     "iopub.status.idle": "2024-07-28T15:13:27.681430Z",
     "shell.execute_reply": "2024-07-28T15:13:27.680402Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.663795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- REDIRECT IB_ASYNC LOGGER ---\n",
    "\n",
    "\n",
    "class LoguruHandler(logging.Handler):\n",
    "    def emit(self, record):\n",
    "        # Convert logging level to Loguru level\n",
    "        loguru_level = logger.level(record.levelname)\n",
    "        logger.log(loguru_level, record.getMessage(), record.args)\n",
    "\n",
    "\n",
    "# Replace ib_async log handler\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.handlers = [LoguruHandler()]\n",
    "\n",
    "# Set the loguru logger\n",
    "logger.add(sink=ROOT / \"log\" / \"nakeds.log\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSE specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.684440Z",
     "iopub.status.busy": "2024-07-28T15:13:27.683416Z",
     "iopub.status.idle": "2024-07-28T15:13:27.719765Z",
     "shell.execute_reply": "2024-07-28T15:13:27.719765Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.684440Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- NSE FUNCTIONS ---\n",
    "# ---------------------\n",
    "\n",
    "def make_earliest_nakeds(fnos: Union[List, set], \n",
    "                         save: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Make all early fnos\"\"\"\n",
    "\n",
    "    timer = Timer(\"Making earliest nakeds\")\n",
    "    timer.start()\n",
    "\n",
    "    dfs = []\n",
    "    suffix = get_pickle_suffix(pattern=\"/*nakeds*\")\n",
    "\n",
    "    for symbol in fnos:\n",
    "\n",
    "        try:\n",
    "            df_nakeds = make_early_opts_for_symbol(symbol, port=port)\n",
    "            df_nakeds = df_nakeds[df_nakeds.xPrice > 0]\n",
    "\n",
    "        except (AttributeError, ValueError) as e:\n",
    "            logger.error(e)\n",
    "            df_nakeds = None\n",
    "\n",
    "        dfs.append(df_nakeds)\n",
    "\n",
    "        # collect dfs and save\n",
    "        if dfs:\n",
    "            try:\n",
    "                df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "            except ValueError as e:\n",
    "                logger.error(f\"No dfs to concat!. Error: {e}\")\n",
    "                df = pd.DataFrame([])\n",
    "\n",
    "            if save and not df.empty:\n",
    "                filename = str(f\"earliest_nakeds{suffix}.pkl\")\n",
    "                pickle_me(df, ROOT / \"data\" / \"raw\" / filename)\n",
    "        else:\n",
    "            df = dfs\n",
    "\n",
    "    timer.stop()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_early_opts_for_symbol(\n",
    "    symbol: str,  # nse_symbol. can be equity or index\n",
    "    port: int,\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"Make target options for nakeds with earliest expiry\n",
    "    \n",
    "    Args:\n",
    "       symbol: can be equity or index\n",
    "       port: int. Could be LIVE_PORT | PAPER_PORT\n",
    "       \"\"\"\n",
    "\n",
    "    # Instantiate nse\n",
    "    nse = NSEfnos()\n",
    "\n",
    "    # Get the basic quote\n",
    "    fno_quote = nse.stock_quote_fno(symbol)\n",
    "\n",
    "    # make the fno df with iv, hv, lot\n",
    "    df_fno = equity_iv_df(fno_quote)\n",
    "\n",
    "    # get margins and commissions from ib\n",
    "    df_mcom = get_ib_margin_comms(df_fno, port=port)\n",
    "\n",
    "    # Remove zero IVs\n",
    "    df_mcom = df_mcom[df_mcom.iv > 0]\n",
    "\n",
    "    # Remove zero DTEs and create a new df\n",
    "    df = df_mcom[df_mcom.dte > 0]\n",
    "\n",
    "    # Get the risk free rate\n",
    "    rbi = RBI()\n",
    "    risk_free_rate = rbi.repo_rate() / 100\n",
    "\n",
    "    # Compute the black_scholes of option strike\n",
    "    bsPrice = df_mcom.apply(\n",
    "        lambda row: black_scholes(\n",
    "            S=row[\"undPrice\"],\n",
    "            K=row[\"strike\"],\n",
    "            T=row[\"dte\"] / 365,  # Convert days to years\n",
    "            r=risk_free_rate,\n",
    "            sigma=row[\"iv\"],\n",
    "            option_type=row[\"right\"],\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Compute the black_scholes price of safe_strike\n",
    "    # get the safe-strike, based on std multiples\n",
    "    df_sp = pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            pd.Series(\n",
    "                df.iv\n",
    "                * df.undPrice\n",
    "                * (df.dte / 365).apply(lambda x: math.sqrt(x) if x >= 0 else np.nan),\n",
    "                name=\"sdev\",\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # calculate safe strike with option price added\n",
    "    safe_strike = np.where(\n",
    "        df_sp.right == \"P\",\n",
    "        (df_sp.undPrice - df_sp.sdev * PUTSTDMULT).astype(\"int\"),\n",
    "        (df_sp.undPrice + df_sp.sdev * CALLSTDMULT).astype(\"int\"),\n",
    "    )\n",
    "\n",
    "    df_sp = df_sp.assign(safe_strike=safe_strike)\n",
    "\n",
    "    # intrinsic value\n",
    "    intrinsic = np.where(\n",
    "        df_sp.right == \"P\",\n",
    "        (df_sp.strike - df_sp.safe_strike).map(lambda x: max(0, x)),\n",
    "        (df_sp.safe_strike - df_sp.strike).map(lambda x: max(0, x)),\n",
    "    )\n",
    "\n",
    "    df_sp = df_sp.assign(intrinsic=intrinsic)\n",
    "\n",
    "    # compute xPrice based on distance from safe_strike\n",
    "    maxPrice = np.maximum(df_sp.price, pd.Series(bsPrice))\n",
    "\n",
    "    # derive expected price from safe_strike\n",
    "    df = df_sp.assign(\n",
    "        xPrice=(df_sp.intrinsic + maxPrice).apply(\n",
    "            lambda x: max(get_prec(x, 0.05), 0.05)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # prevent divide-by-zero error for rom\n",
    "    df = df.assign(margin=np.where(df.margin <= 0, np.nan, df.margin))\n",
    "\n",
    "    # calculate the return on margin (rom)\n",
    "    df = df.assign(rom=df.xPrice * df.lot / df.margin * 365 / df.dte)\n",
    "\n",
    "    # Sort by likeliest\n",
    "    df_out = df.loc[(df.xPrice / df.price).sort_values().index]\n",
    "\n",
    "    return df_out.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def nse_ban_list() -> list:\n",
    "    \"\"\"Gets scrips banned today\"\"\"\n",
    "\n",
    "    url = \"https://nsearchives.nseindia.com/content/fo/fo_secban.csv\"\n",
    "    headers = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 \"\n",
    "        \"(KHTML, like Gecko) \"\n",
    "        \"Chrome/80.0.3987.149 Safari/537.36\",\n",
    "        \"accept-language\": \"en,gu;q=0.9,hi;q=0.8\",\n",
    "        \"accept-encoding\": \"gzip, deflate, br\",\n",
    "    }\n",
    "\n",
    "    base_url = \"https://www.nseindia.com\"\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        request = session.get(base_url, headers=headers, timeout=5)\n",
    "        cookies = dict(request.cookies)\n",
    "        response = session.get(url, headers=headers, timeout=5, cookies=cookies)\n",
    "\n",
    "    df = pd.read_csv(io.StringIO(response.text))\n",
    "    ban_list = df.iloc[:, 0].tolist()\n",
    "\n",
    "    return ban_list\n",
    "\n",
    "\n",
    "def live_cache(app_name):\n",
    "    \"\"\"Caches the output for time_out specified. This is done in order to\n",
    "    prevent hitting live quote requests to NSE too frequently. This wrapper\n",
    "    will fetch the quote/live result first time and return the same result for\n",
    "    any calls within 'time_out' seconds.\n",
    "\n",
    "    Logic:\n",
    "        key = concat of args\n",
    "        try:\n",
    "            cached_value = self._cache[key]\n",
    "            if now - self._cache['tstamp'] < time_out\n",
    "                return cached_value['value']\n",
    "        except AttributeError: # _cache attribute has not been created yet\n",
    "            self._cache = {}\n",
    "        finally:\n",
    "            val = fetch-new-value\n",
    "            new_value = {'tstamp': now, 'value': val}\n",
    "            self._cache[key] = new_value\n",
    "            return val\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        \"\"\"Wrapper function which calls the function only after the timeout,\n",
    "        otherwise returns value from the cache.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get key by just concating the list of args and kwargs values and hope\n",
    "        # that it does not break the code :P\n",
    "        inputs = [str(a) for a in args] + [str(kwargs[k]) for k in kwargs]\n",
    "        key = app_name.__name__ + \"-\".join(inputs)\n",
    "        now = datetime.now()\n",
    "        time_out = self.time_out\n",
    "        try:\n",
    "            cache_obj = self._cache[key]\n",
    "            if now - cache_obj[\"timestamp\"] < timedelta(seconds=time_out):\n",
    "                return cache_obj[\"value\"]\n",
    "        except:\n",
    "            self._cache = {}\n",
    "        value = app_name(self, *args, **kwargs)\n",
    "        self._cache[key] = {\"value\": value, \"timestamp\": now}\n",
    "        return value\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def clean_stock_history(result: list) -> pd.DataFrame:\n",
    "    \"\"\"Cleans output of\"\"\"\n",
    "\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(r.get(\"data\")) for r in result], axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    # ...clean columns\n",
    "\n",
    "    mapping = {\n",
    "        \"CH_SYMBOL\": \"nse_symbol\",\n",
    "        \"TIMESTAMP\": \"date\",\n",
    "        \"CH_OPENING_PRICE\": \"open\",\n",
    "        \"CH_TRADE_HIGH_PRICE\": \"high\",\n",
    "        \"CH_TRADE_LOW_PRICE\": \"low\",\n",
    "        \"CH_CLOSING_PRICE\": \"close\",\n",
    "        \"CH_TOT_TRADED_QTY\": \"qty_traded\",\n",
    "        \"CH_TOT_TRADED_VAL\": \"value_traded\",\n",
    "        \"CH_TOTAL_TRADES\": \"trades\",\n",
    "        \"VWAP\": \"vwap\",\n",
    "        \"updatedAt\": \"extracted_on\",\n",
    "    }\n",
    "\n",
    "    df = df[[col for col in mapping.keys() if col in df.columns]].rename(\n",
    "        columns=mapping\n",
    "    )\n",
    "\n",
    "    # ...convert column datatypes\n",
    "\n",
    "    astype_map = {\n",
    "        **{\n",
    "            k: \"float\"\n",
    "            for k in [\"open\", \"high\", \"low\", \"close\", \"value_traded\", \"trades\", \"vwap\"]\n",
    "        },\n",
    "        **{\"qty_traded\": \"int\"},\n",
    "    }\n",
    "\n",
    "    df = df.astype(astype_map)\n",
    "\n",
    "    # ...change date columns to utc\n",
    "\n",
    "    replace_cols = [\"date\", \"extracted_on\"]\n",
    "    df1 = df[replace_cols].map(lambda x: datetime.fromisoformat(x))\n",
    "    df = df.assign(date=df1.date, extracted_on=df1.extracted_on)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_index_history(results: list) -> pd.DataFrame:\n",
    "    \"\"\"cleans index history and builds it as a dataframe\"\"\"\n",
    "\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(json.loads(r.get(\"d\"))) for r in results], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # clean the df\n",
    "\n",
    "    # ...drop unnecessary columns\n",
    "\n",
    "    df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "\n",
    "    # ...rename\n",
    "    df.columns = [\"nse_symbol\", \"date\", \"open\", \"high\", \"low\", \"close\"]\n",
    "\n",
    "    # ...convert nse_symbol to IB's symbol\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df.nse_symbol.map(IDXHISTSYMMAP).rename(\"symbol\"),\n",
    "            df,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    utc_dates = df.date.apply(lambda x: convert_to_utc_datetime(x, eod=True))\n",
    "\n",
    "    df = df.assign(date=utc_dates)\n",
    "\n",
    "    # .....convert ohlc to numeric\n",
    "    convert_dict = {k: \"float\" for k in [\"open\", \"high\", \"low\", \"close\"]}\n",
    "\n",
    "    df = df.astype(convert_dict)\n",
    "\n",
    "    # .....sort by date\n",
    "    df.sort_values([\"nse_symbol\", \"date\"], inplace=True, ignore_index=True)\n",
    "\n",
    "    # .....add extract_date\n",
    "    now = datetime.now()\n",
    "    utc_now = now.astimezone(timezone.utc)\n",
    "    df = df.assign(extracted_on=utc_now)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def nse2ib(nse_list):\n",
    "    \"\"\"Converts nse to ib friendly symbols\"\"\"\n",
    "\n",
    "    subs = {\"M&M\": \"MM\", \"M&MFIN\": \"MMFIN\", \"L&TFH\": \"LTFH\", \"NIFTY\": \"NIFTY50\"}\n",
    "\n",
    "    list_without_percent_sign = list(map(subs.get, nse_list, nse_list))\n",
    "\n",
    "    # fix length to 9 characters\n",
    "    ib_equity_fnos = [s[:9] for s in list_without_percent_sign]\n",
    "\n",
    "    return ib_equity_fnos\n",
    "\n",
    "\n",
    "def make_date_range_for_stock_history(\n",
    "    symbol: str, days: int = 365, chunks: int = 50\n",
    ") -> list:\n",
    "    \"\"\"Uses `split_dates` to make date range for stock history\"\"\"\n",
    "\n",
    "    date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "    series = \"EQ\"\n",
    "\n",
    "    ranges = [\n",
    "        {\n",
    "            \"symbol\": symbol,\n",
    "            \"from\": start.strftime(\"%d-%m-%Y\"),\n",
    "            \"to\": end.strftime(\"%d-%m-%Y\"),\n",
    "            \"series\": f'[\"{series}\"]',\n",
    "        }\n",
    "        for start, end in date_ranges\n",
    "    ]\n",
    "\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def equity_iv_df(quotes: dict) -> pd.DataFrame:\n",
    "    \"\"\"Build a core df with symbol, undPrice, expiry, strike, volatilities, lot and price.\"\"\"\n",
    "\n",
    "    flat_data = json_normalize(quotes, sep=\"-\")\n",
    "\n",
    "    # get symbol, lot and underlying pricefrom quote\n",
    "\n",
    "    symbol = quotes.get(\"info\").get(\"symbol\")\n",
    "\n",
    "    lot = (\n",
    "        quotes[\"stocks\"][0].get(\"marketDeptOrderBook\").get(\"tradeInfo\").get(\"marketLot\")\n",
    "    )\n",
    "\n",
    "    undPrice = quotes[\"underlyingValue\"]\n",
    "\n",
    "    # build the df\n",
    "    df = pd.DataFrame(flat_data)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"nse_symbol\": symbol,\n",
    "                \"ib_symbol\": symbol,\n",
    "                \"instrument\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"metadata\")\n",
    "                .get(\"instrumentType\"),\n",
    "                \"expiry\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"expiryDate\"),\n",
    "                \"undPrice\": undPrice,\n",
    "                \"safe_strike\": 0,\n",
    "                \"right\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"optionType\")[:1],\n",
    "                \"strike\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"strikePrice\"),\n",
    "                \"dte\": np.nan,\n",
    "                \"hv\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"marketDeptOrderBook\")\n",
    "                .get(\"otherInfo\")\n",
    "                .get(\"annualisedVolatility\"),\n",
    "                \"iv\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"marketDeptOrderBook\")\n",
    "                .get(\"otherInfo\")\n",
    "                .get(\"impliedVolatility\"),\n",
    "                \"lot\": lot,\n",
    "                \"price\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"lastPrice\"),\n",
    "            }\n",
    "            for i in range(len(quotes))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Convert nse_symbol to symbol\n",
    "    df = df.assign(ib_symbol=nse2ib(df.nse_symbol))\n",
    "\n",
    "    # Convert expiry to UTC NSE eod\n",
    "    df = df.assign(\n",
    "        expiry=df.expiry.apply(lambda x: convert_to_utc_datetime(x, eod=True))\n",
    "    )\n",
    "\n",
    "    df = df.assign(dte=get_dte(df.expiry))\n",
    "\n",
    "    # Convert the rest to numeric\n",
    "    df = df.apply(convert_to_numeric)\n",
    "\n",
    "    # Convert to %ge\n",
    "    df.iv = df.iv / 100\n",
    "    df.hv = df.hv / 100\n",
    "\n",
    "    # Change instrument type\n",
    "    instrument_dict = {\n",
    "        \"Stock\": \"STK\",\n",
    "        \"Options\": \"OPT\",\n",
    "        \"Currency\": \"FX\",\n",
    "        \"Index\": \"IDX\",\n",
    "        \"Futures\": \"FUT\",\n",
    "    }\n",
    "\n",
    "    inst = df.instrument.str.split()\n",
    "\n",
    "    s = inst.apply(lambda x: \"\".join(instrument_dict[item] for item in x))\n",
    "\n",
    "    df = df.assign(instrument=s)\n",
    "\n",
    "    df = df[df.instrument.isin([\"IDXOPT\", \"STKOPT\"])]\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.721774Z",
     "iopub.status.busy": "2024-07-28T15:13:27.720771Z",
     "iopub.status.idle": "2024-07-28T15:13:27.739128Z",
     "shell.execute_reply": "2024-07-28T15:13:27.739128Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.720771Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- SET CONSTANTS  ---\n",
    "# ----------------------\n",
    "config = load_config()\n",
    "\n",
    "MARKET = \"NSE\"\n",
    "\n",
    "PUTSTDMULT = config.get(\"PUTSTDMULT\")\n",
    "CALLSTDMULT = config.get(\"CALLSTDMULT\")\n",
    "MINEXPROM = config.get(\"MINEXPROM\")\n",
    "MARGINPERORDER = config.get(\"MARGINPERORDER\")\n",
    "\n",
    "# maps  for nifty and bank nifty\n",
    "IDXHISTSYMMAP = config.get(\"IDXHISTSYMMAP\")\n",
    "\n",
    "# IBKR port access\n",
    "PORT = port = config.get(\"PORT\")\n",
    "# PAPER = config.get('PAPER_PORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools (Utilities) Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.740638Z",
     "iopub.status.busy": "2024-07-28T15:13:27.739128Z",
     "iopub.status.idle": "2024-07-28T15:13:27.748747Z",
     "shell.execute_reply": "2024-07-28T15:13:27.748747Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.740638Z"
    }
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Timer providing elapsed time\"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"\") -> None:\n",
    "        self.name = name\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start a new timer\"\"\"\n",
    "        if self._start_time is not None:\n",
    "            raise Exception(f\"Timer is running. Use .stop() to stop it\")\n",
    "\n",
    "        now = datetime.now()\n",
    "\n",
    "        print(f'\\n{self.name} started at {now.strftime(\"%d-%b-%Y %H: %M:%S\")}')\n",
    "\n",
    "        self._start_time = datetime.now()\n",
    "\n",
    "    def stop(self) -> None:\n",
    "        if self._start_time is None:\n",
    "            raise Exception(f\"Timer is not running. Use .start() to start it\")\n",
    "\n",
    "        elapsed_time = datetime.now() - self._start_time\n",
    "\n",
    "        # Extract hours, minutes, seconds from the timedelta object\n",
    "        hours = elapsed_time.seconds // 3600\n",
    "        minutes = (elapsed_time.seconds % 3600) // 60\n",
    "        seconds = elapsed_time.seconds % 60\n",
    "\n",
    "        print(f\"\\n...{self.name} took: \" + f\"{hours:02d}:{minutes:02d}:{seconds:02d}\\n\")\n",
    "\n",
    "        self._start_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSE specific Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.748747Z",
     "iopub.status.busy": "2024-07-28T15:13:27.748747Z",
     "iopub.status.idle": "2024-07-28T15:13:27.779502Z",
     "shell.execute_reply": "2024-07-28T15:13:27.779502Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.748747Z"
    }
   },
   "outputs": [],
   "source": [
    "class NSEfnos:\n",
    "    \"\"\"Class for All NSE FNOS, including Indexes\"\"\"\n",
    "\n",
    "    time_out = 5\n",
    "    base_url = \"https://www.nseindia.com/api\"\n",
    "    page_url = \"https://www.nseindia.com/get-quotes/equity?symbol=LT\"\n",
    "    _routes = {\n",
    "        \"stock_meta\": \"/equity-meta-info\",\n",
    "        \"stock_quote\": \"/quote-equity\",\n",
    "        \"stock_derivative_quote\": \"/quote-derivative\",\n",
    "        \"market_status\": \"/marketStatus\",\n",
    "        \"chart_data\": \"/chart-databyindex\",\n",
    "        \"market_turnover\": \"/market-turnover\",\n",
    "        \"equity_derivative_turnover\": \"/equity-stock\",\n",
    "        \"all_indices\": \"/allIndices\",\n",
    "        \"live_index\": \"/equity-stockIndices\",\n",
    "        \"index_option_chain\": \"/option-chain-indices\",\n",
    "        \"equity_option_chain\": \"/option-chain-equities\",\n",
    "        \"currency_option_chain\": \"/option-chain-currency\",\n",
    "        \"pre_open_market\": \"/market-data-pre-open\",\n",
    "        \"holiday_list\": \"/holiday-master?type=trading\",\n",
    "        \"stock_history\": \"/historical/cm/equity\",  # added by rkv\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.s = requests.Session()\n",
    "        h = {\n",
    "            \"Host\": \"www.nseindia.com\",\n",
    "            \"Referer\": \"https://www.nseindia.com/get-quotes/equity?symbol=SBIN\",\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"pragma\": \"no-cache\",\n",
    "            \"sec-fetch-dest\": \"empty\",\n",
    "            \"sec-fetch-mode\": \"cors\",\n",
    "            \"sec-fetch-site\": \"same-origin\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\",\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "        }\n",
    "        self.s.headers.update(h)\n",
    "        self.s.get(self.page_url)\n",
    "\n",
    "    def get(self, route, payload={}):\n",
    "        url = self.base_url + self._routes[route]\n",
    "        r = self.s.get(url, params=payload)\n",
    "        return r.json()\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote_fno(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_derivative_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def trade_info(self, symbol):\n",
    "        data = {\"symbol\": symbol, \"section\": \"trade_info\"}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def market_status(self):\n",
    "        return self.get(\"market_status\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def chart_data(self, symbol, indices=False):\n",
    "        data = {\"index\": symbol + \"EQN\"}\n",
    "        if indices:\n",
    "            data[\"index\"] = symbol\n",
    "            data[\"indices\"] = \"true\"\n",
    "        return self.get(\"chart_data\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def tick_data(self, symbol, indices=False):\n",
    "        return self.chart_data(symbol, indices)\n",
    "\n",
    "    @live_cache\n",
    "    def market_turnover(self):\n",
    "        return self.get(\"market_turnover\")\n",
    "\n",
    "    @live_cache\n",
    "    def eq_derivative_turnover(self, type=\"allcontracts\"):\n",
    "        data = {\"index\": type}\n",
    "        return self.get(\"equity_derivative_turnover\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def all_indices(self):\n",
    "        return self.get(\"all_indices\")\n",
    "\n",
    "    def live_index(self, symbol=\"NIFTY 50\"):\n",
    "        data = {\"index\": symbol}\n",
    "        return self.get(\"live_index\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def index_option_chain(self, symbol=\"NIFTY\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"index_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def equities_option_chain(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"equity_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def currency_option_chain(self, symbol=\"USDINR\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"currency_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def live_fno(self):\n",
    "        return self.live_index(\"SECURITIES IN F&O\")\n",
    "\n",
    "    @live_cache\n",
    "    def pre_open_market(self, key=\"NIFTY\"):\n",
    "        data = {\"key\": key}\n",
    "        return self.get(\"pre_open_market\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def holiday_list(self):\n",
    "        return self.get(\"holiday_list\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def stock_history(self, symbol, days: int = 365, chunks: int = 50):\n",
    "\n",
    "        date_ranges = make_date_range_for_stock_history(symbol, days, chunks)\n",
    "\n",
    "        result = []\n",
    "        for dr in date_ranges:\n",
    "            result.append(self.get(\"stock_history\", dr))\n",
    "\n",
    "        df = clean_stock_history(result)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def equities(self, sort_me: bool=True) -> set:\n",
    "        \n",
    "        equities_data = self.live_fno()\n",
    "        equities = [kv.get(\"symbol\") for kv in equities_data.get(\"data\")]\n",
    "        if sort_me:\n",
    "            equities.sort()\n",
    "\n",
    "        return set(equities)\n",
    "\n",
    "    def indexes(self):\n",
    "        x = \"NIFTY,BANKNIFTY,MIDCPNIFTY,NIFTYNXT50,FINNIFTY\"\n",
    "        return set(x.split(\",\"))\n",
    "\n",
    "\n",
    "class IDXHistories:\n",
    "\n",
    "    time_out = 5\n",
    "    base_url = \"https://niftyindices.com\"\n",
    "    idx_symbols = IDXHISTSYMMAP.values()\n",
    "    url = \"https://niftyindices.com/Backpage.aspx/getHistoricaldatatabletoString\"\n",
    "\n",
    "    # prepare `post` header\n",
    "    post_header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"sec-ch-ua\": '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"',\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"Content-Type\": \"application/json; charset=UTF-8\",\n",
    "        \"Origin\": \"https://niftyindices.com\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Referer\": \"https://niftyindices.com/reports/historical-data\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,hi;q=0.8\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, days: int = 365) -> None:\n",
    "        self.s = requests.Session()\n",
    "\n",
    "        # update session with default headers and get the cookies\n",
    "        init_header = requests.utils.default_headers()\n",
    "        init_header.update(\n",
    "            {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "            }\n",
    "        )\n",
    "        self.s.headers.update(init_header)\n",
    "        c = self.s.get(url=self.url)\n",
    "        self.cookies = c.cookies\n",
    "\n",
    "    def get(self, payload={}):\n",
    "\n",
    "        r = self.s.post(\n",
    "            url=self.url,\n",
    "            headers=self.post_header,\n",
    "            cookies=self.cookies,\n",
    "            data=payload,\n",
    "            timeout=self.time_out,\n",
    "        )\n",
    "\n",
    "        return r.json()\n",
    "\n",
    "    def make_histories(self, days: int = 365, chunks: int = 50):\n",
    "        \"\"\"Makes histories for NIFTY50 and BANKNIFTY, based on number of days provided\"\"\"\n",
    "\n",
    "        date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "        # idx_symbols = [\"Nifty Bank\", \"Nifty 50\"]\n",
    "\n",
    "        # organize the payloads\n",
    "        payloads = [\n",
    "            {\n",
    "                \"cinfo\": str(\n",
    "                    {\n",
    "                        \"name\": idx_symbol,\n",
    "                        \"startDate\": s.strftime(\"%d-%b-%Y\"),\n",
    "                        \"endDate\": e.strftime(\"%d-%b-%Y\"),\n",
    "                        \"indexName\": idx_symbol,\n",
    "                    }\n",
    "                )\n",
    "            }\n",
    "            for s, e in date_ranges\n",
    "            for idx_symbol in self.idx_symbols\n",
    "        ]\n",
    "        # get the raw jsons\n",
    "        results = []\n",
    "\n",
    "        for payload in tqdm(payloads):\n",
    "            r = self.get(payload=json.dumps(payload))\n",
    "            results.append(r)\n",
    "\n",
    "        df = clean_index_history(results)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def rbi_tr_to_json(wrapper):\n",
    "    trs = wrapper.find_all(\"tr\")\n",
    "    op = {}\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all(\"td\")\n",
    "        if len(tds) >= 2:\n",
    "            key = tds[0].text.strip()\n",
    "            val = tds[1].text.replace(\":\", \"\").replace(\"*\", \"\").replace(\"#\", \"\").strip()\n",
    "\n",
    "            op[key] = val\n",
    "    return op\n",
    "\n",
    "\n",
    "class RBI:\n",
    "    base_url = \"https://www.rbi.org.in/\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.s = requests.Session()\n",
    "\n",
    "    def current_rates(self):\n",
    "        r = self.s.get(self.base_url)\n",
    "\n",
    "        bs = BeautifulSoup(r.text, \"html.parser\")\n",
    "        wrapper = bs.find(\"div\", {\"id\": \"wrapper\"})\n",
    "\n",
    "        return rbi_tr_to_json(wrapper)\n",
    "\n",
    "    def repo_rate(self):\n",
    "\n",
    "        rate = self.current_rates().get(\"Policy Repo Rate\")[:-1]\n",
    "\n",
    "        return float(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T17:06:20.253191Z",
     "iopub.status.busy": "2024-07-27T17:06:20.229563Z",
     "iopub.status.idle": "2024-07-27T17:06:20.360868Z",
     "shell.execute_reply": "2024-07-27T17:06:20.360868Z",
     "shell.execute_reply.started": "2024-07-27T17:06:20.253191Z"
    }
   },
   "source": [
    "## ibfunc Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.782510Z",
     "iopub.status.busy": "2024-07-28T15:13:27.781512Z",
     "iopub.status.idle": "2024-07-28T15:13:27.793885Z",
     "shell.execute_reply": "2024-07-28T15:13:27.792872Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.781512Z"
    }
   },
   "outputs": [],
   "source": [
    "def empty_the_df(df):\n",
    "    \"\"\"Empty the dataclass df\"\"\"\n",
    "    empty_df = pd.DataFrame([df.__dict__]).iloc[0:0]\n",
    "    return empty_df\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OpenOrder:\n",
    "    \"\"\"\n",
    "    Open order template with Dummy data. Use:\\n\n",
    "    `df = OpenOrder().empty()`\n",
    "    \"\"\"\n",
    "\n",
    "    conId: int = 0\n",
    "    symbol: str = \"Dummy\"\n",
    "    secType: str = \"STK\"\n",
    "    expiry: datetime = datetime.now()\n",
    "    strike: float = 0.0\n",
    "    right: str = \"?\"  # Will be 'P' for Put, 'C' for Call\n",
    "    orderId: int = 0\n",
    "    order: Order = None\n",
    "    permId: int = 0\n",
    "    action: str = \"SELL\"  # 'BUY' | 'SELL'\n",
    "    totalQuantity: float = 0.0\n",
    "    lmtPrice: float = 0.0\n",
    "    status: str = None\n",
    "\n",
    "    def empty(self):\n",
    "        return empty_the_df(self)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Portfolio:\n",
    "    \"\"\"\n",
    "    Portfolio template with Dummy data. Use:\\n\n",
    "    `df = OpenOrder().empty()`\n",
    "    \"\"\"\n",
    "\n",
    "    conId: int = 0\n",
    "    symbol: str = \"Dummy\"\n",
    "    secType: str = \"STK\"\n",
    "    expiry: datetime = datetime.now()\n",
    "    strike: float = 0.0\n",
    "    right: str = \"?\"  # Will be 'P' for Put, 'C' for Call\n",
    "    position: float = 0.0\n",
    "    mktPrice: float = 0.0\n",
    "    mktVal: float = 0.0\n",
    "    avgCost: float = 0.0\n",
    "    unPnL: float = 0.0\n",
    "    rePnL: float = 0.0\n",
    "\n",
    "    def empty(self):\n",
    "        return empty_the_df(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG TEST (`run.py`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate nakeds pickles and put them to history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.794883Z",
     "iopub.status.busy": "2024-07-28T15:13:27.794883Z",
     "iopub.status.idle": "2024-07-28T15:13:27.812013Z",
     "shell.execute_reply": "2024-07-28T15:13:27.812013Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.794883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No raw files to archive\n"
     ]
    }
   ],
   "source": [
    "# Check if there is anything in the `raw` data folder [utils.py]\n",
    "\n",
    "def handle_raws(): \n",
    "    raw_files = get_files_from_patterns()\n",
    "    if raw_files:\n",
    "        ans = yes_or_no(\"Do you want to archive raw nakeds?\")\n",
    "    \n",
    "        if ans:\n",
    "            remove_raw_nakeds(save=True)\n",
    "\n",
    "    else:\n",
    "        print(\"No raw files to archive\")\n",
    "\n",
    "\n",
    "handle_raws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:13:27.813793Z",
     "iopub.status.busy": "2024-07-28T15:13:27.813793Z",
     "iopub.status.idle": "2024-07-28T15:13:30.447585Z",
     "shell.execute_reply": "2024-07-28T15:13:30.447585Z",
     "shell.execute_reply.started": "2024-07-28T15:13:27.813793Z"
    }
   },
   "outputs": [],
   "source": [
    "# get set of executed symbols from df_naked\n",
    "symbols_list = [get_pickle(ROOT / \"data\" / \"df_nakeds.pkl\").nse_symbol.to_list()]\n",
    "executed = set(chain.from_iterable(symbols_list)) # takes care of nested lists\n",
    "\n",
    "# get open order symbols\n",
    "with IB().connect(port=port, clientId=10) as ib:\n",
    "\n",
    "    trades = ib.reqAllOpenOrders()\n",
    "    df_pf = quick_pf(ib)\n",
    "    try:\n",
    "        df_openords = get_open_orders(ib)\n",
    "        open_orders = set(df_openords.symbol.to_list())\n",
    "    except UnboundLocalError as e:\n",
    "        logger.info(f\"No open orders found\")\n",
    "        open_orders = set()  # empty\n",
    "\n",
    "# Build the fnos list\n",
    "# ... initialize fno class\n",
    "nse = NSEfnos()\n",
    "\n",
    "fnos = ((set([\"BANKNIFTY\", \"NIFTY\"]) | nse.equities()) - executed) - open_orders\n",
    "fnos = list(fnos - set(nse_ban_list()))\n",
    "fnos.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Earliest Nakeds\n",
    "<span style='color:red'><b>Do `Esc+r+y` to convert following to code and build fresh nakeds<br>\n",
    "Do `Esc+r` to make it back to raw mode</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-28T15:10:32.402489Z",
     "iopub.status.idle": "2024-07-28T15:10:32.404436Z",
     "shell.execute_reply": "2024-07-28T15:10:32.403337Z",
     "shell.execute_reply.started": "2024-07-28T15:10:32.403337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build the earliest naked options\n",
    "\n",
    "if fnos:\n",
    "    df_nakeds = make_earliest_nakeds(fnos, save=True)\n",
    "\n",
    "    out = {\n",
    "        \"current_#fnos\": len(fnos),\n",
    "        \"unique_symbols\": len(df_nakeds.ib_symbol.unique()),\n",
    "        \"# of orders\": len(df_nakeds),\n",
    "    }\n",
    "else:\n",
    "    df = get_pickle(ROOT/\"data\"/\"df_nakeds.pkl\")\n",
    "    df_nakeds = arrange_orders(df, maxmargin=MARGINPERORDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing the orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-28T15:10:32.405731Z",
     "iopub.status.idle": "2024-07-28T15:10:32.405731Z",
     "shell.execute_reply": "2024-07-28T15:10:32.405731Z",
     "shell.execute_reply.started": "2024-07-28T15:10:32.405731Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- PREPARE ORDERS\n",
    "\n",
    "def make_ib_orders(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Make (contract, order) tuples\"\"\"\n",
    "\n",
    "    contracts = df.contract.to_list()\n",
    "    orders = [\n",
    "        LimitOrder(action=\"SELL\", totalQuantity=abs(int(q)), lmtPrice=p)\n",
    "        for q, p in zip(df.lot, df.xPrice)\n",
    "    ]\n",
    "\n",
    "    cos = tuple((c, o) for c, o in zip(contracts, orders))\n",
    "\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-28T15:10:32.408186Z",
     "iopub.status.idle": "2024-07-28T15:10:32.408186Z",
     "shell.execute_reply": "2024-07-28T15:10:32.408186Z",
     "shell.execute_reply.started": "2024-07-28T15:10:32.408186Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = get_pickle(ROOT/\"data\"/\"df_nakeds.pkl\")\n",
    "df_nakeds = arrange_orders(df, maxmargin=MARGINPERORDER)\n",
    "\n",
    "# cos = make_ib_orders(df_nakeds)\n",
    "make_ib_orders(df_nakeds)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLACE THE ORDER"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# --- PLACE ORDERS\n",
    "with IB().connect(port=3000) as ib:\n",
    "    ordered = place_orders(ib=ib, cos=cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the orders placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:20:52.907575Z",
     "iopub.status.busy": "2024-07-28T15:20:52.906054Z",
     "iopub.status.idle": "2024-07-28T15:20:53.417380Z",
     "shell.execute_reply": "2024-07-28T15:20:53.416289Z",
     "shell.execute_reply.started": "2024-07-28T15:20:52.906054Z"
    }
   },
   "outputs": [],
   "source": [
    "with IB().connect(port=port, clientId=10) as ib:\n",
    "    df_openords = get_open_orders(ib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:21:56.307228Z",
     "iopub.status.busy": "2024-07-28T15:21:56.298700Z",
     "iopub.status.idle": "2024-07-28T15:21:56.327205Z",
     "shell.execute_reply": "2024-07-28T15:21:56.326184Z",
     "shell.execute_reply.started": "2024-07-28T15:21:56.307228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conId</th>\n",
       "      <th>symbol</th>\n",
       "      <th>secType</th>\n",
       "      <th>expiry</th>\n",
       "      <th>strike</th>\n",
       "      <th>right</th>\n",
       "      <th>orderId</th>\n",
       "      <th>order</th>\n",
       "      <th>permId</th>\n",
       "      <th>action</th>\n",
       "      <th>totalQuantity</th>\n",
       "      <th>lmtPrice</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>712930003</td>\n",
       "      <td>PEL</td>\n",
       "      <td>OPT</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>C</td>\n",
       "      <td>84644</td>\n",
       "      <td>Order(orderId=84644, clientId=1, permId=696504...</td>\n",
       "      <td>696504735</td>\n",
       "      <td>SELL</td>\n",
       "      <td>750.0</td>\n",
       "      <td>137.55</td>\n",
       "      <td>PreSubmitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>707116646</td>\n",
       "      <td>PEL</td>\n",
       "      <td>OPT</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>900.0</td>\n",
       "      <td>P</td>\n",
       "      <td>84935</td>\n",
       "      <td>Order(orderId=84935, clientId=1, permId=696505...</td>\n",
       "      <td>696505026</td>\n",
       "      <td>SELL</td>\n",
       "      <td>750.0</td>\n",
       "      <td>68.55</td>\n",
       "      <td>PreSubmitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>709219458</td>\n",
       "      <td>PEL</td>\n",
       "      <td>OPT</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>C</td>\n",
       "      <td>84961</td>\n",
       "      <td>Order(orderId=84961, clientId=1, permId=696505...</td>\n",
       "      <td>696505052</td>\n",
       "      <td>SELL</td>\n",
       "      <td>750.0</td>\n",
       "      <td>81.00</td>\n",
       "      <td>PreSubmitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         conId symbol secType     expiry  strike right  orderId  \\\n",
       "0    712930003    PEL     OPT 2024-08-29  1050.0     C    84644   \n",
       "246  707116646    PEL     OPT 2024-08-29   900.0     P    84935   \n",
       "276  709219458    PEL     OPT 2024-08-29  1100.0     C    84961   \n",
       "\n",
       "                                                 order     permId action  \\\n",
       "0    Order(orderId=84644, clientId=1, permId=696504...  696504735   SELL   \n",
       "246  Order(orderId=84935, clientId=1, permId=696505...  696505026   SELL   \n",
       "276  Order(orderId=84961, clientId=1, permId=696505...  696505052   SELL   \n",
       "\n",
       "     totalQuantity  lmtPrice        status  \n",
       "0            750.0    137.55  PreSubmitted  \n",
       "246          750.0     68.55  PreSubmitted  \n",
       "276          750.0     81.00  PreSubmitted  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = df_openords.symbol == 'PEL'\n",
    "df_openords[m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying the order price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:25:27.265628Z",
     "iopub.status.busy": "2024-07-28T15:25:27.259603Z",
     "iopub.status.idle": "2024-07-28T15:25:27.276558Z",
     "shell.execute_reply": "2024-07-28T15:25:27.273866Z",
     "shell.execute_reply.started": "2024-07-28T15:25:27.265628Z"
    }
   },
   "outputs": [],
   "source": [
    "from ib_async import Contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:27:32.580868Z",
     "iopub.status.busy": "2024-07-28T15:27:32.579861Z",
     "iopub.status.idle": "2024-07-28T15:27:32.595323Z",
     "shell.execute_reply": "2024-07-28T15:27:32.593308Z",
     "shell.execute_reply.started": "2024-07-28T15:27:32.580868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Order(orderId=84644, clientId=1, permId=696504735, action='SELL', totalQuantity=750.0, orderType='LMT', lmtPrice=137.55, auxPrice=0.0, tif='DAY', ocaType=3, displaySize=2147483647, rule80A='0', openClose='', volatilityType=0, deltaNeutralOrderType='None', referencePriceType=0, account='U9329809', clearingIntent='IB', adjustedOrderType='None', cashQty=0.0, dontUseAutoPriceForHedge=True),\n",
       " 712930003)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openords.iloc[0].order, int(df_openords.iloc[0].conId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:30:16.866280Z",
     "iopub.status.busy": "2024-07-28T15:30:16.865279Z",
     "iopub.status.idle": "2024-07-28T15:30:17.314296Z",
     "shell.execute_reply": "2024-07-28T15:30:17.314296Z",
     "shell.execute_reply.started": "2024-07-28T15:30:16.866280Z"
    }
   },
   "outputs": [],
   "source": [
    "order, conId = df_openords.iloc[0].order, int(df_openords.iloc[0].conId)\n",
    "order.lmtPrice = order.lmtPrice + 0.75\n",
    "\n",
    "with IB().connect(port=port, clientId=10) as ib:\n",
    "    contract = ib.qualifyContracts(Contract(conId=conId))[0]\n",
    "    p = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:32:44.796904Z",
     "iopub.status.busy": "2024-07-28T15:32:44.794916Z",
     "iopub.status.idle": "2024-07-28T15:32:44.812455Z",
     "shell.execute_reply": "2024-07-28T15:32:44.810380Z",
     "shell.execute_reply.started": "2024-07-28T15:32:44.796904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.25"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.order.lmtPrice - 137.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:33:04.209457Z",
     "iopub.status.busy": "2024-07-28T15:33:04.209457Z",
     "iopub.status.idle": "2024-07-28T15:33:04.232360Z",
     "shell.execute_reply": "2024-07-28T15:33:04.230328Z",
     "shell.execute_reply.started": "2024-07-28T15:33:04.209457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(139.8-137.55)/0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:29:00.029793Z",
     "iopub.status.busy": "2024-07-28T15:29:00.028794Z",
     "iopub.status.idle": "2024-07-28T15:29:00.041212Z",
     "shell.execute_reply": "2024-07-28T15:29:00.039144Z",
     "shell.execute_reply.started": "2024-07-28T15:29:00.029793Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Test Bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TEST BED ---\n",
    "# ----------------\n",
    "\n",
    "\n",
    "def cancel_open_orders(ib) -> pd.DataFrame:\n",
    "    \"\"\"!!!Not working!!! --- CHECK\"\"\"\n",
    "\n",
    "    trades = ib.reqAllOpenOrders()  # To kickstart collection of open orders\n",
    "    ib.sleep(0.3)\n",
    "    trades = ib.trades()  # Get the trades\n",
    "\n",
    "    orders = {\n",
    "        t.order\n",
    "        for t in trades\n",
    "        if t.orderStatus.status == \"Submitted\"\n",
    "        if t.order.action == \"SELL\"\n",
    "    }\n",
    "\n",
    "    # df_open_orders = get_open_orders(ib)\n",
    "    # ords = df_open_orders.order.to_list()\n",
    "\n",
    "    BLK = 25\n",
    "    ords = list(orders)\n",
    "    o_blk = [ords[i : i + BLK] for i in range(0, len(ords), BLK)]\n",
    "\n",
    "    cancels = []\n",
    "\n",
    "    for ob in o_blk:\n",
    "        cancels.append([ib.cancelOrder(o) for o in ob])\n",
    "        ib.sleep(0.3)\n",
    "\n",
    "    return cancels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Price (Stock Only! NOT FOR INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"RELIANCE\"\n",
    "q = nse.stock_quote(symbol)\n",
    "\n",
    "stock_price = q.get(\"priceInfo\").get(\"lastPrice\")\n",
    "\n",
    "stock_price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
