{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get one symbol nakeds for `NSE`\n",
    "***\n",
    "\n",
    "- [x] get equity fno list\n",
    "- [x] get equity histories\n",
    "- [x] get index histories\n",
    "- [x] get lot-size\n",
    "- [x] get market price of options\n",
    "- [x] get volatilities for chains\n",
    "- [x] get option closest to underlying\n",
    "- [x] get all chains with dte\n",
    "\n",
    "***\n",
    "\n",
    "- [ ] get rim SDs based on SDMULT and dte\n",
    "- [ ] get margins\n",
    "- [ ] get equity option histories\n",
    "- [ ] get index option histories\n",
    "\n",
    "***\n",
    " - [ ] pack all into symbol objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CELL SHOULD BE IN ALL VSCODE NOTEBOOKS ##\n",
    "\n",
    "MARKET = \"NSE\"\n",
    "\n",
    "# Set the root\n",
    "from from_root import from_root\n",
    "\n",
    "ROOT = from_root()\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add `src` and ROOT to _src.pth in .venv to allow imports in VS Code\n",
    "from sysconfig import get_path\n",
    "\n",
    "if \"src\" not in Path.cwd().parts:\n",
    "    src_path = str(Path(get_path(\"purelib\")) / \"_src.pth\")\n",
    "    with open(src_path, \"w\") as f:\n",
    "        f.write(str(ROOT / \"src\\n\"))\n",
    "        f.write(str(ROOT))\n",
    "        if str(ROOT) not in sys.path:\n",
    "            sys.path.insert(1, str(ROOT))\n",
    "\n",
    "# Start the Jupyter loop\n",
    "from ib_async import util\n",
    "\n",
    "util.startLoop()\n",
    "\n",
    "logger.add(sink=ROOT / \"log\" / \"ztest.log\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from datetime import date, datetime, time, timedelta, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pytz\n",
    "import requests\n",
    "from pandas import json_normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import create_dataclass_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUTSTDMULT = 2\n",
    "CALLSTDMULT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "# ****************\n",
    "\n",
    "\n",
    "def live_cache(app_name):\n",
    "    \"\"\"Caches the output for time_out specified. This is done in order to\n",
    "    prevent hitting live quote requests to NSE too frequently. This wrapper\n",
    "    will fetch the quote/live result first time and return the same result for\n",
    "    any calls within 'time_out' seconds.\n",
    "\n",
    "    Logic:\n",
    "        key = concat of args\n",
    "        try:\n",
    "            cached_value = self._cache[key]\n",
    "            if now - self._cache['tstamp'] < time_out\n",
    "                return cached_value['value']\n",
    "        except AttributeError: # _cache attribute has not been created yet\n",
    "            self._cache = {}\n",
    "        finally:\n",
    "            val = fetch-new-value\n",
    "            new_value = {'tstamp': now, 'value': val}\n",
    "            self._cache[key] = new_value\n",
    "            return val\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        \"\"\"Wrapper function which calls the function only after the timeout,\n",
    "        otherwise returns value from the cache.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get key by just concating the list of args and kwargs values and hope\n",
    "        # that it does not break the code :P\n",
    "        inputs = [str(a) for a in args] + [str(kwargs[k]) for k in kwargs]\n",
    "        key = app_name.__name__ + \"-\".join(inputs)\n",
    "        now = datetime.now()\n",
    "        time_out = self.time_out\n",
    "        try:\n",
    "            cache_obj = self._cache[key]\n",
    "            if now - cache_obj[\"timestamp\"] < timedelta(seconds=time_out):\n",
    "                return cache_obj[\"value\"]\n",
    "        except:\n",
    "            self._cache = {}\n",
    "        value = app_name(self, *args, **kwargs)\n",
    "        self._cache[key] = {\"value\": value, \"timestamp\": now}\n",
    "        return value\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def split_dates(days: int = 365, chunks: int = 50) -> list:\n",
    "    \"\"\"splits dates into buckets, based on chunks\"\"\"\n",
    "\n",
    "    end = datetime.today()\n",
    "    periods = int(days / chunks)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    if days < chunks:\n",
    "        date_ranges = [(start, end)]\n",
    "    else:\n",
    "        dates = pd.date_range(start, end, periods).date\n",
    "        date_ranges = list(\n",
    "            zip(pd.Series(dates), pd.Series(dates).shift(-1) + timedelta(days=-1))\n",
    "        )[:-1]\n",
    "\n",
    "    # remove last tuple having period as NaT\n",
    "    if any(pd.isna(e) for element in date_ranges for e in element):\n",
    "        date_ranges = date_ranges[:-1]\n",
    "\n",
    "    return date_ranges\n",
    "\n",
    "\n",
    "def make_date_range_for_stock_history(\n",
    "    symbol: str, days: int = 365, chunks: int = 50\n",
    ") -> list:\n",
    "    \"\"\"Uses `split_dates` to make date range for stock history\"\"\"\n",
    "\n",
    "    date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "    series = \"EQ\"\n",
    "\n",
    "    ranges = [\n",
    "        {\n",
    "            \"symbol\": symbol,\n",
    "            \"from\": start.strftime(\"%d-%m-%Y\"),\n",
    "            \"to\": end.strftime(\"%d-%m-%Y\"),\n",
    "            \"series\": f'[\"{series}\"]',\n",
    "        }\n",
    "        for start, end in date_ranges\n",
    "    ]\n",
    "\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def clean_stock_history(result: list) -> pd.DataFrame:\n",
    "    \"\"\"Cleans output of\"\"\"\n",
    "\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(r.get(\"data\")) for r in result], axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    # ...clean columns\n",
    "\n",
    "    mapping = {\n",
    "        \"CH_SYMBOL\": \"nse_symbol\",\n",
    "        \"TIMESTAMP\": \"date\",\n",
    "        \"CH_OPENING_PRICE\": \"open\",\n",
    "        \"CH_TRADE_HIGH_PRICE\": \"high\",\n",
    "        \"CH_TRADE_LOW_PRICE\": \"low\",\n",
    "        \"CH_CLOSING_PRICE\": \"close\",\n",
    "        \"CH_TOT_TRADED_QTY\": \"qty_traded\",\n",
    "        \"CH_TOT_TRADED_VAL\": \"value_traded\",\n",
    "        \"CH_TOTAL_TRADES\": \"trades\",\n",
    "        \"VWAP\": \"vwap\",\n",
    "        \"updatedAt\": \"extracted_on\",\n",
    "    }\n",
    "\n",
    "    df = df[[col for col in mapping.keys() if col in df.columns]].rename(\n",
    "        columns=mapping\n",
    "    )\n",
    "\n",
    "    # ...convert column datatypes\n",
    "\n",
    "    astype_map = {\n",
    "        **{\n",
    "            k: \"float\"\n",
    "            for k in [\"open\", \"high\", \"low\", \"close\", \"value_traded\", \"trades\", \"vwap\"]\n",
    "        },\n",
    "        **{\"qty_traded\": \"int\"},\n",
    "    }\n",
    "\n",
    "    df = df.astype(astype_map)\n",
    "\n",
    "    # ...change date columns to utc\n",
    "\n",
    "    replace_cols = [\"date\", \"extracted_on\"]\n",
    "    df1 = df[replace_cols].map(lambda x: datetime.fromisoformat(x))\n",
    "    df = df.assign(date=df1.date, extracted_on=df1.extracted_on)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_index_history(results: list) -> pd.DataFrame:\n",
    "    \"\"\"cleans index history and builds it as a dataframe\"\"\"\n",
    "\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(json.loads(r.get(\"d\"))) for r in results], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # clean the df\n",
    "\n",
    "    # ...drop unnecessary columns\n",
    "\n",
    "    df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "\n",
    "    # ...rename\n",
    "    df.columns = [\"nse_symbol\", \"date\", \"open\", \"high\", \"low\", \"close\"]\n",
    "\n",
    "    # ...convert nse_symbol to IB's symbol\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df.nse_symbol.map(\n",
    "                {\"Nifty Bank\": \"BANKNIFTY\", \"Nifty 50\": \"NIFTY50\"}\n",
    "            ).rename(\"symbol\"),\n",
    "            df,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    utc_dates = dates_string_to_utc(df.date, eod=True)\n",
    "\n",
    "    df = df.assign(date=utc_dates)\n",
    "\n",
    "    # .....convert ohlc to numeric\n",
    "    convert_dict = {k: \"float\" for k in [\"open\", \"high\", \"low\", \"close\"]}\n",
    "\n",
    "    df = df.astype(convert_dict)\n",
    "\n",
    "    # .....sort by date\n",
    "    df.sort_values([\"nse_symbol\", \"date\"], inplace=True, ignore_index=True)\n",
    "\n",
    "    # .....add extract_date\n",
    "    now = datetime.now()\n",
    "    utc_now = now.astimezone(timezone.utc)\n",
    "    df = df.assign(extracted_on=utc_now)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def nse2ib(nse_list):\n",
    "    \"\"\"Converts nse to ib friendly symbols\"\"\"\n",
    "\n",
    "    subs = {\"M&M\": \"MM\", \"M&MFIN\": \"MMFIN\", \"L&TFH\": \"LTFH\", \"NIFTY\": \"NIFTY50\"}\n",
    "\n",
    "    list_without_percent_sign = list(map(subs.get, nse_list, nse_list))\n",
    "\n",
    "    # fix length to 9 characters\n",
    "    ib_equity_fnos = [s[:9] for s in list_without_percent_sign]\n",
    "\n",
    "    return ib_equity_fnos\n",
    "\n",
    "\n",
    "def convert_to_utc_datetime(date_string, eod=False):\n",
    "    \"\"\"Converts nse date strings to utc datetimes. If eod is chosen 3:30 PM IST is taken.\"\"\"\n",
    "\n",
    "    # List of possible date formats\n",
    "    date_formats = [\"%d-%b-%Y\", \"%d %b %Y\", \"%Y-%m-%d %H:%M:%S.%f%z\"]\n",
    "\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            dt = datetime.strptime(date_string, date_format)\n",
    "\n",
    "            # If the parsed datetime doesn't have timezone info, assume it's UTC\n",
    "            if dt.tzinfo is None:\n",
    "                dt = dt.replace(tzinfo=pytz.UTC)\n",
    "            else:\n",
    "                # If it has timezone info, convert to UTC\n",
    "                dt = dt.astimezone(pytz.UTC)\n",
    "\n",
    "            if eod:\n",
    "                # Set time to 3:30 PM India time for all formats when eod is True\n",
    "                india_time = time(hour=15, minute=30)\n",
    "                india_tz = pytz.timezone(\"Asia/Kolkata\")\n",
    "                dt = india_tz.localize(datetime.combine(dt.date(), india_time))\n",
    "                dt = dt.astimezone(pytz.UTC)\n",
    "            elif dt.time() == time(0, 0):  # If time is midnight (00:00:00)\n",
    "                # Keep it as midnight UTC\n",
    "                dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # If none of the formats work, raise an error\n",
    "    raise ValueError(f\"Unable to parse date string: {date_string}\")\n",
    "\n",
    "\n",
    "def convert_to_numeric(col: pd.Series):\n",
    "    \"\"\"convert to numeric if possible, only for object dtypes\"\"\"\n",
    "\n",
    "    if col.dtype == \"object\":\n",
    "        try:\n",
    "            return pd.to_numeric(col)\n",
    "        except ValueError:\n",
    "            return col\n",
    "    return col\n",
    "\n",
    "\n",
    "def convert_daily_volatility_to_yearly(daily_volatility, days: float = 252):\n",
    "    return daily_volatility * math.sqrt(days)\n",
    "\n",
    "\n",
    "def equity_iv_df(quotes: dict) -> pd.DataFrame:\n",
    "    \"\"\"Build a core df with symbol, undPrice, expiry, strike, volatilities, lot and price.\"\"\"\n",
    "\n",
    "    flat_data = json_normalize(quotes, sep=\"-\")\n",
    "\n",
    "    # get lot from quote\n",
    "    lot = (\n",
    "        quotes[\"stocks\"][0].get(\"marketDeptOrderBook\").get(\"tradeInfo\").get(\"marketLot\")\n",
    "    )\n",
    "\n",
    "    # build the df\n",
    "    df = pd.DataFrame(flat_data)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"symbol\": symbol,\n",
    "                \"instrument\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"metadata\")\n",
    "                .get(\"instrumentType\"),\n",
    "                \"undPrice\": stock_price,\n",
    "                \"expiry\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"expiryDate\"),\n",
    "                \"strike\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"strikePrice\"),\n",
    "                \"hv\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"marketDeptOrderBook\")\n",
    "                .get(\"otherInfo\")\n",
    "                .get(\"annualisedVolatility\"),\n",
    "                \"iv\": quotes.get(\"stocks\")[i]\n",
    "                .get(\"marketDeptOrderBook\")\n",
    "                .get(\"otherInfo\")\n",
    "                .get(\"impliedVolatility\"),\n",
    "                \"lot\": lot,\n",
    "                \"price\": quotes.get(\"stocks\")[i].get(\"metadata\").get(\"lastPrice\"),\n",
    "            }\n",
    "            for i in range(len(quotes))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Convert expiry to UTC NSE eod\n",
    "    df = df.assign(\n",
    "        expiry=df.expiry.apply(lambda x: convert_to_utc_datetime(x, eod=True))\n",
    "    )\n",
    "\n",
    "    # Convert the rest to numeric\n",
    "    df = df.apply(convert_to_numeric)\n",
    "\n",
    "    # Change instrument type\n",
    "    instrument_dict = {\n",
    "        \"Stock\": \"STK\",\n",
    "        \"Options\": \"OPT\",\n",
    "        \"Currency\": \"FX\",\n",
    "        \"Index\": \"IDX\",\n",
    "        \"Futures\": \"FUT\",\n",
    "    }\n",
    "\n",
    "    inst = df.instrument.str.split()\n",
    "\n",
    "    s = inst.apply(lambda x: \"\".join(instrument_dict[item] for item in x))\n",
    "\n",
    "    df = df.assign(instrument=s)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_closest_strike(df, above=False):\n",
    "    \"\"\"\n",
    "    Finds the row with the strike closest to the undPrice.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    above (bool): If True, find the closest strike above undPrice. If False, find the closest strike below undPrice.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the single row that has the closest strike.\n",
    "    \"\"\"\n",
    "    undPrice = df[\"undPrice\"].iloc[0]  # Get the undPrice from the first row\n",
    "\n",
    "    if above:\n",
    "        # Filter for strikes above undPrice\n",
    "        mask = df[\"strike\"] > undPrice\n",
    "    else:\n",
    "        # Filter for strikes below undPrice\n",
    "        mask = df[\"strike\"] < undPrice\n",
    "\n",
    "    if not mask.any():\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no rows match the criteria\n",
    "\n",
    "    # Calculate the absolute difference between strike and undPrice\n",
    "    diff = np.abs(df.loc[mask, \"strike\"] - undPrice)\n",
    "\n",
    "    # Find the index of the row with the minimum difference\n",
    "    closest_index = diff.idxmin()\n",
    "\n",
    "    # Return the closest row as a DataFrame\n",
    "    return df.loc[[closest_index]]\n",
    "\n",
    "\n",
    "def get_dte(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Gets days to expiry. Expects series of UTC timestamps\"\"\"\n",
    "\n",
    "    now_utc = datetime.now(pytz.UTC)\n",
    "    return (s - now_utc).dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "\n",
    "def fbfillnas(ser: pd.Series) -> pd.Series:\n",
    "    \"\"\"Fills nan in series forwards first and then backwards\"\"\"\n",
    "\n",
    "    s = ser.copy()\n",
    "\n",
    "    # Find the first non-NaN value\n",
    "    first_non_nan = s.dropna().iloc[0]\n",
    "\n",
    "    # Fill first NaN with the first non-NaN value\n",
    "    s.iloc[0] = first_non_nan\n",
    "\n",
    "    # Fill remaining NaN values with the next valid value\n",
    "    s = s.fillna(s.bfill())\n",
    "\n",
    "    # Fill remaining NaN values with the previous valid value\n",
    "    s = s.fillna(s.ffill())\n",
    "\n",
    "    return ser.fillna(s)\n",
    "\n",
    "\n",
    "def get_a_stdev(iv: float, price: float, dte: float) -> float:\n",
    "    \"\"\"Gives 1 Standard Deviation value for annual iv\"\"\"\n",
    "    \n",
    "    return iv * price * math.sqrt(dte / 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES\n",
    "# *******\n",
    "\n",
    "\n",
    "class Stocks:\n",
    "    time_out = 5\n",
    "    base_url = \"https://www.nseindia.com/api\"\n",
    "    page_url = \"https://www.nseindia.com/get-quotes/equity?symbol=LT\"\n",
    "    _routes = {\n",
    "        \"stock_meta\": \"/equity-meta-info\",\n",
    "        \"stock_quote\": \"/quote-equity\",\n",
    "        \"stock_derivative_quote\": \"/quote-derivative\",\n",
    "        \"market_status\": \"/marketStatus\",\n",
    "        \"chart_data\": \"/chart-databyindex\",\n",
    "        \"market_turnover\": \"/market-turnover\",\n",
    "        \"equity_derivative_turnover\": \"/equity-stock\",\n",
    "        \"all_indices\": \"/allIndices\",\n",
    "        \"live_index\": \"/equity-stockIndices\",\n",
    "        \"index_option_chain\": \"/option-chain-indices\",\n",
    "        \"equity_option_chain\": \"/option-chain-equities\",\n",
    "        \"currency_option_chain\": \"/option-chain-currency\",\n",
    "        \"pre_open_market\": \"/market-data-pre-open\",\n",
    "        \"holiday_list\": \"/holiday-master?type=trading\",\n",
    "        \"stock_history\": \"/historical/cm/equity\",  # added by rkv\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.s = requests.Session()\n",
    "        h = {\n",
    "            \"Host\": \"www.nseindia.com\",\n",
    "            \"Referer\": \"https://www.nseindia.com/get-quotes/equity?symbol=SBIN\",\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"pragma\": \"no-cache\",\n",
    "            \"sec-fetch-dest\": \"empty\",\n",
    "            \"sec-fetch-mode\": \"cors\",\n",
    "            \"sec-fetch-site\": \"same-origin\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\",\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "        }\n",
    "        self.s.headers.update(h)\n",
    "        self.s.get(self.page_url)\n",
    "\n",
    "    def get(self, route, payload={}):\n",
    "        url = self.base_url + self._routes[route]\n",
    "        r = self.s.get(url, params=payload)\n",
    "        return r.json()\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote_fno(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_derivative_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def trade_info(self, symbol):\n",
    "        data = {\"symbol\": symbol, \"section\": \"trade_info\"}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def market_status(self):\n",
    "        return self.get(\"market_status\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def chart_data(self, symbol, indices=False):\n",
    "        data = {\"index\": symbol + \"EQN\"}\n",
    "        if indices:\n",
    "            data[\"index\"] = symbol\n",
    "            data[\"indices\"] = \"true\"\n",
    "        return self.get(\"chart_data\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def tick_data(self, symbol, indices=False):\n",
    "        return self.chart_data(symbol, indices)\n",
    "\n",
    "    @live_cache\n",
    "    def market_turnover(self):\n",
    "        return self.get(\"market_turnover\")\n",
    "\n",
    "    @live_cache\n",
    "    def eq_derivative_turnover(self, type=\"allcontracts\"):\n",
    "        data = {\"index\": type}\n",
    "        return self.get(\"equity_derivative_turnover\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def all_indices(self):\n",
    "        return self.get(\"all_indices\")\n",
    "\n",
    "    def live_index(self, symbol=\"NIFTY 50\"):\n",
    "        data = {\"index\": symbol}\n",
    "        return self.get(\"live_index\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def index_option_chain(self, symbol=\"NIFTY\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"index_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def equities_option_chain(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"equity_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def currency_option_chain(self, symbol=\"USDINR\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"currency_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def live_fno(self):\n",
    "        return self.live_index(\"SECURITIES IN F&O\")\n",
    "\n",
    "    @live_cache\n",
    "    def pre_open_market(self, key=\"NIFTY\"):\n",
    "        data = {\"key\": key}\n",
    "        return self.get(\"pre_open_market\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def holiday_list(self):\n",
    "        return self.get(\"holiday_list\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def stock_history(self, symbol, days: int = 365, chunks: int = 50):\n",
    "\n",
    "        date_ranges = make_date_range_for_stock_history(symbol, days, chunks)\n",
    "\n",
    "        result = []\n",
    "        for dr in date_ranges:\n",
    "            result.append(self.get(\"stock_history\", dr))\n",
    "\n",
    "        df = clean_stock_history(result)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "class IDXHistories:\n",
    "\n",
    "    time_out = 5\n",
    "    base_url = \"https://niftyindices.com\"\n",
    "    url = \"https://niftyindices.com/Backpage.aspx/getHistoricaldatatabletoString\"\n",
    "\n",
    "    # prepare `post` header\n",
    "    post_header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"sec-ch-ua\": '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"',\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"Content-Type\": \"application/json; charset=UTF-8\",\n",
    "        \"Origin\": \"https://niftyindices.com\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Referer\": \"https://niftyindices.com/reports/historical-data\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,hi;q=0.8\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, days: int = 365) -> None:\n",
    "        self.s = requests.Session()\n",
    "\n",
    "        # update session with default headers and get the cookies\n",
    "        init_header = requests.utils.default_headers()\n",
    "        init_header.update(\n",
    "            {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "            }\n",
    "        )\n",
    "        self.s.headers.update(init_header)\n",
    "        c = self.s.get(url=self.url)\n",
    "        self.cookies = c.cookies\n",
    "\n",
    "    def get(self, payload={}):\n",
    "\n",
    "        r = self.s.post(\n",
    "            url=self.url,\n",
    "            headers=self.post_header,\n",
    "            cookies=self.cookies,\n",
    "            data=payload,\n",
    "            timeout=self.time_out,\n",
    "        )\n",
    "\n",
    "        return r.json()\n",
    "\n",
    "    def make_histories(self, days: int = 365, chunks: int = 50):\n",
    "        \"\"\"Makes histories for NIFTY50 and BANKNIFTY, based on number of days provided\"\"\"\n",
    "\n",
    "        date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "        idx_symbols = [\"Nifty Bank\", \"Nifty 50\"]\n",
    "\n",
    "        # organize the payloads\n",
    "        payloads = [\n",
    "            {\n",
    "                \"cinfo\": str(\n",
    "                    {\n",
    "                        \"name\": idx_symbol,\n",
    "                        \"startDate\": s.strftime(\"%d-%b-%Y\"),\n",
    "                        \"endDate\": e.strftime(\"%d-%b-%Y\"),\n",
    "                        \"indexName\": idx_symbol,\n",
    "                    }\n",
    "                )\n",
    "            }\n",
    "            for s, e in date_ranges\n",
    "            for idx_symbol in idx_symbols\n",
    "        ]\n",
    "        # get the raw jsons\n",
    "        results = []\n",
    "\n",
    "        for payload in tqdm(payloads):\n",
    "            r = self.get(payload=json.dumps(payload))\n",
    "            results.append(r)\n",
    "\n",
    "        df = clean_index_history(results)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock FnOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize `Stocks` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse = Stocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get underlying price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"SBIN\"\n",
    "\n",
    "q = nse.stock_quote(symbol)\n",
    "stock_price = q.get(\"priceInfo\").get(\"lastPrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get equity fno list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equities = nse.live_fno()\n",
    "\n",
    "# Equities set\n",
    "fno_equities = {kv.get(\"symbol\") for kv in equities.get(\"data\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a stock quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = nse.stock_quote_fno(symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lot from a stock quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot = quotes[\"stocks\"][0].get(\"marketDeptOrderBook\").get(\"tradeInfo\").get(\"marketLot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get hv and iv with lot from fno quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vola = equity_iv_df(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vola.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find strike closest to underlying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_to_und = find_closest_strike(df_vola, above=False)\n",
    "closest_to_und"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get underlying volatlities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatilities = next(iter(quotes.get(\"underlyingInfo\").get(\"volatility\")))\n",
    "\n",
    "und_vols = {\n",
    "    k: convert_daily_volatility_to_yearly(float(v)) for k, v in volatilities.items()\n",
    "}\n",
    "\n",
    "und_vols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Stock History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nse.stock_history(\"ongc\", days=365, chunks=50)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index History\n",
    " - Index histories are treated in a separate class as:\n",
    "     - its URL (https://niftyindices.com) is different than equity\n",
    "     - which needs a POST after of a GET request\n",
    "     - and also has its date string with a dash (20-Jul-2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Index Histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = IDXHistories()\n",
    "\n",
    "df_idx_hist = idx.make_histories(20)  # give number of days needed\n",
    "\n",
    "df_idx_hist.groupby(\"symbol\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_chain = nse.equities_option_chain(symbol)  # Equity option chains\n",
    "data = stock_chain.get(\"records\").get(\"data\")\n",
    "\n",
    "# idx_chain = nse.index_option_chain(\"NIFTY\")  # Index Option chains\n",
    "# data = idx_chain.get('records').get('data')\n",
    "\n",
    "pe = [data[i].get(\"PE\") for i in range(len(data))]\n",
    "df_pe = json_normalize(pe, sep=\"-\").dropna(subset=[\"identifier\"])\n",
    "# df_pe = df_pe.sort_values('strikePrice', ascending=False).reset_index(drop=True)\n",
    "df_pe[\"right\"] = \"P\"\n",
    "\n",
    "ce = [data[i].get(\"CE\") for i in range(len(data))]\n",
    "df_ce = json_normalize(ce, sep=\"-\").dropna(subset=[\"identifier\"])\n",
    "df_ce[\"right\"] = \"C\"\n",
    "# df_ce = df_ce.sort_values('strikePrice', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([df_ce, df_pe], ignore_index=True)\n",
    "\n",
    "chain_col_map = {\n",
    "    \"underlying\": \"symbol\",\n",
    "    \"underlyingValue\": \"undPrice\",\n",
    "    \"expiryDate\": \"expiry\",\n",
    "    \"strikePrice\": \"strike\",\n",
    "    \"right\": \"right\",\n",
    "    \"openInterest\": \"oi\",\n",
    "    \"changeinOpenInterest\": \"oi_chg\",\n",
    "    \"pchangeinOpenInterest\": \"oi_pchg\",\n",
    "    \"totalTradedVolume\": \"volume\",\n",
    "    \"change\": \"change\",\n",
    "    \"pChange\": \"ltp_pct_chg\",\n",
    "    \"totalBuyQuantity\": \"buy_qty\",\n",
    "    \"totalSellQuantity\": \"sell_qty\",\n",
    "    \"bidQty\": \"bid_qty\",\n",
    "    \"bidprice\": \"bid\",\n",
    "    \"askQty\": \"ask_qty\",\n",
    "    \"askPrice\": \"ask\",\n",
    "    \"impliedVolatility\": \"iv\",\n",
    "    \"dte\": \"dte\",\n",
    "    \"stdev\": \"stdev\",\n",
    "    \"lastPrice\": \"ltp\",\n",
    "}\n",
    "\n",
    "df.rename(columns=chain_col_map, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Convert expiry to UTC NSE eod\n",
    "df = df.assign(expiry=df.expiry.apply(lambda x: convert_to_utc_datetime(x, eod=True)))\n",
    "\n",
    "# Convert the rest to numeric\n",
    "df = df.apply(convert_to_numeric)\n",
    "\n",
    "# Replace zero values of iv and ltp to np.nan\n",
    "df[\"iv\"] = df[\"iv\"].replace(0, np.nan)\n",
    "df[\"ltp\"] = df[\"ltp\"].replace(0, np.nan)\n",
    "\n",
    "# Gets dte\n",
    "df[\"dte\"] = get_dte(df.expiry)\n",
    "\n",
    "# Sort the columns\n",
    "df = df.sort_values(\n",
    "    [\"dte\", \"right\", \"strike\"], ascending=[True, True, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Fill missing ivs\n",
    "df.iv = fbfillnas(df.iv)\n",
    "\n",
    "# Get standard deviations of strike from underlying.\n",
    "## ... NOTE: iv is divided by 100 to make it into %ge\n",
    "\n",
    "stdev = df.apply(\n",
    "    lambda row: get_a_stdev(iv=row[\"iv\"]/100, price=row[\"undPrice\"], dte=row[\"dte\"]), axis=1\n",
    ")\n",
    "\n",
    "df = df.assign(stdev=stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_values(myArr: list, \n",
    "                       myNumber: float, \n",
    "                       how_many: int=0):\n",
    "    \n",
    "    \"\"\"Get closest values in a list\n",
    "    \n",
    "    how_many: 0 gives the closest value\\n\n",
    "              1 | 2 | ... use for CALL fences\\n\n",
    "             -1 | -2 | ... use for PUT fences\"\"\"\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    result = []\n",
    "\n",
    "    while i <= abs(how_many):\n",
    "\n",
    "        if how_many > 0:\n",
    "            # going right\n",
    "            val = myArr[myArr > myNumber].min()\n",
    "            \n",
    "        elif how_many < 0:\n",
    "            # going left\n",
    "            val = myArr[myArr < myNumber].max()\n",
    "            \n",
    "        else:\n",
    "            val = min(myArr.tolist(), key=lambda x: abs(x-myNumber))\n",
    "\n",
    "        result.append(val)\n",
    "        myNumber = val\n",
    "        i +=1\n",
    "\n",
    "    output = result[0:abs(1 if how_many == 0 else abs(how_many))]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df[df.right == 'C']\n",
    "closest_devs = dfc.groupby('dte').stdev.apply(lambda x: get_closest_values(x, CALLSTDMULT, 1)[0])\n",
    "closest_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcs = dfc[dfc.stdev.isin(closest_devs.to_list())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns to show\n",
    "chain_cols = [v for _, v in chain_col_map.items() if v in df.columns]\n",
    "dfcs[chain_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strike = list(range(100, 150, 5))[1:]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte = [5, 10]*int(len(strike)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(strike)\n",
    "random_numbers = np.random.rand(size)\n",
    "\n",
    "nan_probability = 0.3\n",
    "nan_mask = np.random.random(size) < nan_probability\n",
    "iv = np.where(nan_mask, np.nan, random_numbers)\n",
    "\n",
    "p_choice = 0.5\n",
    "c_choice = 1 - p_choice\n",
    "\n",
    "right = np.random.choice(['P', 'C'], size, p=[p_choice, c_choice])\n",
    "\n",
    "marker = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'strike': strike, 'dte': dte, 'iv': iv, 'right': right})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_closest_iv(df, marker):\n",
    "  \"\"\"Chooses the closest iv value to marker for each group in df.\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): Dataframe containing columns 'strike', 'dte', 'iv', and 'right'.\n",
    "      marker (float): The value to which the closest iv should be chosen.\n",
    "\n",
    "  Returns:\n",
    "      pd.DataFrame: A new DataFrame with the same columns as the input df,\n",
    "                    but with the 'iv' column replaced by the closest values.\n",
    "  \"\"\"\n",
    "\n",
    "  def g(group):\n",
    "    \"\"\"Function applied to each group in df.\n",
    "\n",
    "    Args:\n",
    "        group (pd.DataFrame): A subgroup of df based on 'dte' and 'right'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The group with the 'iv' column replaced by the closest values.\n",
    "    \"\"\"\n",
    "    if group['right'].iloc[0] == 'P':\n",
    "      # For Put options, choose the closest value below marker\n",
    "      return group[group['iv'] <= marker].sort_values(by='iv', ascending=False).head(1)\n",
    "    else:\n",
    "      # For Call options, choose the closest value above marker\n",
    "      return group[group['iv'] >= marker].sort_values(by='iv', ascending=True).head(1)\n",
    "\n",
    "  return df.groupby(['dte', 'right']).apply(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_closest_iv(df.copy(), marker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .... STOPPED HERE for `RIM` options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_chain = nse.index_option_chain(\"NIFTY\")  # Index Option chains\n",
    "curr_option_chain = nse.currency_option_chain(\"USDINR\")  # Currency option chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert nse to ib friendly symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fnos = nse.live_fno()\n",
    "fno_list = {data.get(\"symbol\") for data in raw_fnos.get(\"data\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
