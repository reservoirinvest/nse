{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get one symbol nakeds\n",
    "\n",
    " - [x] get equity fno list\n",
    " - [x] get equity histories\n",
    " - [x] get index histories\n",
    " - [x] get lot-sizes\n",
    " - [x] get market price\n",
    "***\n",
    "\n",
    " - [ ] get volatility\n",
    " - [ ] get chains\n",
    " - [ ] get rim SDs\n",
    " - [ ] retest SDs\n",
    " - [ ] get margins\n",
    " - [ ] pack into symbol objects\n",
    "\n",
    "\n",
    " - [ ] get equity option histories\n",
    " - [ ] get index option histories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CELL SHOULD BE IN ALL VSCODE NOTEBOOKS ##\n",
    "\n",
    "MARKET = \"NSE\"\n",
    "\n",
    "# Set the root\n",
    "from from_root import from_root\n",
    "\n",
    "ROOT = from_root()\n",
    "\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add `src` and ROOT to _src.pth in .venv to allow imports in VS Code\n",
    "from sysconfig import get_path\n",
    "\n",
    "if \"src\" not in Path.cwd().parts:\n",
    "    src_path = str(Path(get_path(\"purelib\")) / \"_src.pth\")\n",
    "    with open(src_path, \"w\") as f:\n",
    "        f.write(str(ROOT / \"src\\n\"))\n",
    "        f.write(str(ROOT))\n",
    "        if str(ROOT) not in sys.path:\n",
    "            sys.path.insert(1, str(ROOT))\n",
    "\n",
    "# Start the Jupyter loop\n",
    "from ib_async import util\n",
    "\n",
    "util.startLoop()\n",
    "\n",
    "logger.add(sink=ROOT / \"log\" / \"ztest.log\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import create_dataclass_from_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dates(days: int = 365, chunks: int = 50) -> list:\n",
    "    \"\"\"splits dates into buckets, based on chunks\"\"\"\n",
    "\n",
    "    end = datetime.today()\n",
    "    periods = int(days / chunks)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    if days < chunks:\n",
    "        date_ranges = [(start, end)]\n",
    "    else:\n",
    "        dates = pd.date_range(start, end, periods).date\n",
    "        date_ranges = list(\n",
    "            zip(pd.Series(dates), pd.Series(dates).shift(-1) + timedelta(days=-1))\n",
    "        )[:-1]\n",
    "\n",
    "    # remove last tuple having period as NaT\n",
    "    if any(pd.isna(e) for element in date_ranges for e in element):\n",
    "        date_ranges = date_ranges[:-1]\n",
    "\n",
    "    return date_ranges\n",
    "\n",
    "\n",
    "def make_date_range_for_stock_history(\n",
    "    symbol: str, days: int = 365, chunks: int = 50\n",
    ") -> list:\n",
    "    \"\"\"Uses `split_dates` to make date range for stock history\"\"\"\n",
    "\n",
    "    date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "    series = \"EQ\"\n",
    "\n",
    "    ranges = [\n",
    "        {\n",
    "            \"symbol\": symbol,\n",
    "            \"from\": start.strftime(\"%d-%m-%Y\"),\n",
    "            \"to\": end.strftime(\"%d-%m-%Y\"),\n",
    "            \"series\": f'[\"{series}\"]',\n",
    "        }\n",
    "        for start, end in date_ranges\n",
    "    ]\n",
    "\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def clean_stock_history(result: list) -> pd.DataFrame:\n",
    "    \"\"\"Cleans output of\"\"\"\n",
    "\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(r.get(\"data\")) for r in result], axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    # ...clean columns\n",
    "\n",
    "    mapping = {\n",
    "        \"CH_SYMBOL\": \"nse_symbol\",\n",
    "        \"TIMESTAMP\": \"date\",\n",
    "        \"CH_OPENING_PRICE\": \"open\",\n",
    "        \"CH_TRADE_HIGH_PRICE\": \"high\",\n",
    "        \"CH_TRADE_LOW_PRICE\": \"low\",\n",
    "        \"CH_CLOSING_PRICE\": \"close\",\n",
    "        \"CH_TOT_TRADED_QTY\": \"qty_traded\",\n",
    "        \"CH_TOT_TRADED_VAL\": \"value_traded\",\n",
    "        \"CH_TOTAL_TRADES\": \"trades\",\n",
    "        \"VWAP\": \"vwap\",\n",
    "        \"updatedAt\": \"extracted_on\",\n",
    "    }\n",
    "\n",
    "    df = df[[col for col in mapping.keys() if col in df.columns]].rename(\n",
    "        columns=mapping\n",
    "    )\n",
    "\n",
    "    # ...convert column datatypes\n",
    "\n",
    "    astype_map = {\n",
    "        **{\n",
    "            k: \"float\"\n",
    "            for k in [\"open\", \"high\", \"low\", \"close\", \"value_traded\", \"trades\", \"vwap\"]\n",
    "        },\n",
    "        **{\"qty_traded\": \"int\"},\n",
    "    }\n",
    "\n",
    "    df = df.astype(astype_map)\n",
    "\n",
    "    # ...change date columns to utc\n",
    "\n",
    "    replace_cols = [\"date\", \"extracted_on\"]\n",
    "    df1 = df[replace_cols].map(lambda x: datetime.fromisoformat(x))\n",
    "    df = df.assign(date=df1.date, extracted_on=df1.extracted_on)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_index_history(results: list) -> pd.DataFrame:\n",
    "    # build the dataframe\n",
    "    df = pd.concat(\n",
    "        [pd.DataFrame(json.loads(r.get(\"d\"))) for r in results], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # clean the df\n",
    "\n",
    "    # ...drop unnecessary columns\n",
    "\n",
    "    df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "\n",
    "    # ...rename\n",
    "    df.columns = [\"nse_symbol\", \"date\", \"open\", \"high\", \"low\", \"close\"]\n",
    "\n",
    "    # ...convert nse_symbol to IB's symbol\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df.nse_symbol.map(\n",
    "                {\"Nifty Bank\": \"BANKNIFTY\", \"Nifty 50\": \"NIFTY50\"}\n",
    "            ).rename(\"symbol\"),\n",
    "            df,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    # ...convert dates to UTC 3:30 PM IST (market close time)\n",
    "    dates = df.date\n",
    "\n",
    "    # .....specify desired timezone offset (Asia/Kolkata is UTC+5:30)\n",
    "    tz_offset = timezone(timedelta(hours=5, minutes=30))\n",
    "\n",
    "    # .....parse dates with specified format and set time to 3:30 PM IST\n",
    "    datetime_series = pd.to_datetime(dates, format=\"%d %b %Y\") + pd.Timedelta(\n",
    "        hours=15, minutes=30\n",
    "    )\n",
    "\n",
    "    # .....convert to UTC with desired offset\n",
    "    utc_dates = datetime_series.dt.tz_localize(tz_offset)\n",
    "\n",
    "    df = df.assign(date=utc_dates)\n",
    "\n",
    "    # .....convert ohlc to numeric\n",
    "    convert_dict = {k: \"float\" for k in [\"open\", \"high\", \"low\", \"close\"]}\n",
    "\n",
    "    df = df.astype(convert_dict)\n",
    "\n",
    "    # .....sort by date\n",
    "    df.sort_values([\"nse_symbol\", \"date\"], inplace=True, ignore_index=True)\n",
    "\n",
    "    # .....add extract_date\n",
    "    now = datetime.now()\n",
    "    utc_now = now.astimezone(timezone.utc)\n",
    "    df = df.assign(extracted_on=utc_now)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def nse2ib(nse_list):\n",
    "    \"\"\"Converts nse to ib friendly symbols\"\"\"\n",
    "\n",
    "    subs = {\"M&M\": \"MM\", \"M&MFIN\": \"MMFIN\", \"L&TFH\": \"LTFH\", \"NIFTY\": \"NIFTY50\"}\n",
    "\n",
    "    list_without_percent_sign = list(map(subs.get, nse_list, nse_list))\n",
    "\n",
    "    # fix length to 9 characters\n",
    "    ib_equity_fnos = [s[:9] for s in list_without_percent_sign]\n",
    "\n",
    "    return ib_equity_fnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_cache(app_name):\n",
    "    \"\"\"Caches the output for time_out specified. This is done in order to\n",
    "    prevent hitting live quote requests to NSE too frequently. This wrapper\n",
    "    will fetch the quote/live result first time and return the same result for\n",
    "    any calls within 'time_out' seconds.\n",
    "\n",
    "    Logic:\n",
    "        key = concat of args\n",
    "        try:\n",
    "            cached_value = self._cache[key]\n",
    "            if now - self._cache['tstamp'] < time_out\n",
    "                return cached_value['value']\n",
    "        except AttributeError: # _cache attribute has not been created yet\n",
    "            self._cache = {}\n",
    "        finally:\n",
    "            val = fetch-new-value\n",
    "            new_value = {'tstamp': now, 'value': val}\n",
    "            self._cache[key] = new_value\n",
    "            return val\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        \"\"\"Wrapper function which calls the function only after the timeout,\n",
    "        otherwise returns value from the cache.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get key by just concating the list of args and kwargs values and hope\n",
    "        # that it does not break the code :P\n",
    "        inputs = [str(a) for a in args] + [str(kwargs[k]) for k in kwargs]\n",
    "        key = app_name.__name__ + \"-\".join(inputs)\n",
    "        now = datetime.now()\n",
    "        time_out = self.time_out\n",
    "        try:\n",
    "            cache_obj = self._cache[key]\n",
    "            if now - cache_obj[\"timestamp\"] < timedelta(seconds=time_out):\n",
    "                return cache_obj[\"value\"]\n",
    "        except:\n",
    "            self._cache = {}\n",
    "        value = app_name(self, *args, **kwargs)\n",
    "        self._cache[key] = {\"value\": value, \"timestamp\": now}\n",
    "        return value\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSELive:\n",
    "    time_out = 5\n",
    "    base_url = \"https://www.nseindia.com/api\"\n",
    "    page_url = \"https://www.nseindia.com/get-quotes/equity?symbol=LT\"\n",
    "    _routes = {\n",
    "        \"stock_meta\": \"/equity-meta-info\",\n",
    "        \"stock_quote\": \"/quote-equity\",\n",
    "        \"stock_derivative_quote\": \"/quote-derivative\",\n",
    "        \"market_status\": \"/marketStatus\",\n",
    "        \"chart_data\": \"/chart-databyindex\",\n",
    "        \"market_turnover\": \"/market-turnover\",\n",
    "        \"equity_derivative_turnover\": \"/equity-stock\",\n",
    "        \"all_indices\": \"/allIndices\",\n",
    "        \"live_index\": \"/equity-stockIndices\",\n",
    "        \"index_option_chain\": \"/option-chain-indices\",\n",
    "        \"equity_option_chain\": \"/option-chain-equities\",\n",
    "        \"currency_option_chain\": \"/option-chain-currency\",\n",
    "        \"pre_open_market\": \"/market-data-pre-open\",\n",
    "        \"holiday_list\": \"/holiday-master?type=trading\",\n",
    "        \"stock_history\": \"/historical/cm/equity\",  # added by rkv\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.s = requests.Session()\n",
    "        h = {\n",
    "            \"Host\": \"www.nseindia.com\",\n",
    "            \"Referer\": \"https://www.nseindia.com/get-quotes/equity?symbol=SBIN\",\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"pragma\": \"no-cache\",\n",
    "            \"sec-fetch-dest\": \"empty\",\n",
    "            \"sec-fetch-mode\": \"cors\",\n",
    "            \"sec-fetch-site\": \"same-origin\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\",\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "        }\n",
    "        self.s.headers.update(h)\n",
    "        self.s.get(self.page_url)\n",
    "\n",
    "    def get(self, route, payload={}):\n",
    "        url = self.base_url + self._routes[route]\n",
    "        r = self.s.get(url, params=payload)\n",
    "        return r.json()\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote_fno(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_derivative_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def trade_info(self, symbol):\n",
    "        data = {\"symbol\": symbol, \"section\": \"trade_info\"}\n",
    "        return self.get(\"stock_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def market_status(self):\n",
    "        return self.get(\"market_status\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def chart_data(self, symbol, indices=False):\n",
    "        data = {\"index\": symbol + \"EQN\"}\n",
    "        if indices:\n",
    "            data[\"index\"] = symbol\n",
    "            data[\"indices\"] = \"true\"\n",
    "        return self.get(\"chart_data\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def tick_data(self, symbol, indices=False):\n",
    "        return self.chart_data(symbol, indices)\n",
    "\n",
    "    @live_cache\n",
    "    def market_turnover(self):\n",
    "        return self.get(\"market_turnover\")\n",
    "\n",
    "    @live_cache\n",
    "    def eq_derivative_turnover(self, type=\"allcontracts\"):\n",
    "        data = {\"index\": type}\n",
    "        return self.get(\"equity_derivative_turnover\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def all_indices(self):\n",
    "        return self.get(\"all_indices\")\n",
    "\n",
    "    def live_index(self, symbol=\"NIFTY 50\"):\n",
    "        data = {\"index\": symbol}\n",
    "        return self.get(\"live_index\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def index_option_chain(self, symbol=\"NIFTY\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"index_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def equities_option_chain(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"equity_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def currency_option_chain(self, symbol=\"USDINR\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"currency_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def live_fno(self):\n",
    "        return self.live_index(\"SECURITIES IN F&O\")\n",
    "\n",
    "    @live_cache\n",
    "    def pre_open_market(self, key=\"NIFTY\"):\n",
    "        data = {\"key\": key}\n",
    "        return self.get(\"pre_open_market\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def holiday_list(self):\n",
    "        return self.get(\"holiday_list\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def stock_history(self, symbol, days: int = 365, chunks: int = 50):\n",
    "\n",
    "        date_ranges = make_date_range_for_stock_history(symbol, days, chunks)\n",
    "\n",
    "        result = []\n",
    "        for dr in date_ranges:\n",
    "            result.append(self.get(\"stock_history\", dr))\n",
    "\n",
    "        df = clean_stock_history(result)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Equity FnOs from `NSElive`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize NSELive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse = NSELive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'SBIN'\n",
    "\n",
    "q = nse.stock_quote(symbol)\n",
    "q.get('priceInfo').get('lastPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Equity fno list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equities = nse.live_fno()\n",
    "\n",
    "# Equities set\n",
    "fno_equities = {kv.get(\"symbol\") for kv in equities.get(\"data\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "\n",
    "quotes = nse.stock_quote_fno(symbol)\n",
    "flat_data = json_normalize(quotes, sep=\"-\")\n",
    "df = pd.DataFrame(flat_data)\n",
    "\n",
    "lot = quotes[\"stocks\"][0].get(\"marketDeptOrderBook\").get(\"tradeInfo\").get(\"marketLot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get volatilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes.get('stocks')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{q.get('identifier'): (symbol, q.get('marketDeptOrderBook').get('annualisedVolatility'), q.get('impliedVolatility')) for q in [quotes.get('stocks')[i].get('metadata') for i in range(len(quotes.get('stocks')))]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Stock History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nse.stock_history(\"ongc\", days=365, chunks=50)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDXHistories:\n",
    "\n",
    "    time_out = 5\n",
    "    base_url = \"https://niftyindices.com\"\n",
    "    url = \"https://niftyindices.com/Backpage.aspx/getHistoricaldatatabletoString\"\n",
    "\n",
    "    # prepare `post` header\n",
    "    post_header = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"sec-ch-ua\": '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"',\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"Content-Type\": \"application/json; charset=UTF-8\",\n",
    "        \"Origin\": \"https://niftyindices.com\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Referer\": \"https://niftyindices.com/reports/historical-data\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,hi;q=0.8\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, days: int = 365) -> None:\n",
    "        self.s = requests.Session()\n",
    "\n",
    "        # update session with default headers and get the cookies\n",
    "        init_header = requests.utils.default_headers()\n",
    "        init_header.update(\n",
    "            {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/91.0.4472.77 Safari/537.36\",\n",
    "            }\n",
    "        )\n",
    "        self.s.headers.update(init_header)\n",
    "        c = self.s.get(url=self.url)\n",
    "        self.cookies = c.cookies\n",
    "\n",
    "    def get(self, payload={}):\n",
    "\n",
    "        r = self.s.post(\n",
    "            url=self.url,\n",
    "            headers=self.post_header,\n",
    "            cookies=self.cookies,\n",
    "            data=payload,\n",
    "            timeout=self.time_out,\n",
    "        )\n",
    "\n",
    "        return r.json()\n",
    "\n",
    "    def make_histories(self, days: int = 365, chunks: int = 50):\n",
    "        \"\"\"Makes histories for NIFTY50 and BANKNIFTY, based on number of days provided\"\"\"\n",
    "\n",
    "        date_ranges = split_dates(days=days, chunks=chunks)\n",
    "\n",
    "        idx_symbols = [\"Nifty Bank\", \"Nifty 50\"]\n",
    "\n",
    "        # organize the payloads\n",
    "        payloads = [\n",
    "            {\n",
    "                \"cinfo\": str(\n",
    "                    {\n",
    "                        \"name\": idx_symbol,\n",
    "                        \"startDate\": s.strftime(\"%d-%b-%Y\"),\n",
    "                        \"endDate\": e.strftime(\"%d-%b-%Y\"),\n",
    "                        \"indexName\": idx_symbol,\n",
    "                    }\n",
    "                )\n",
    "            }\n",
    "            for s, e in date_ranges\n",
    "            for idx_symbol in idx_symbols\n",
    "        ]\n",
    "        # get the raw jsons\n",
    "        results = []\n",
    "\n",
    "        for payload in tqdm(payloads):\n",
    "            r = self.get(payload=json.dumps(payload))\n",
    "            results.append(r)\n",
    "\n",
    "        df = clean_index_history(results)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Index Histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = IDXHistories()\n",
    "\n",
    "df_idx_hist = idx.make_histories(20)  # give number of days needed\n",
    "\n",
    "df_idx_hist.groupby(\"symbol\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_normalize(df[\"stocks\"].iloc[0], sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes[\"stocks\"][0].get(\"marketDeptOrderBook\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_chain = nse.index_option_chain(\"NIFTY\")  # Index Option chains\n",
    "eq_option_chain = nse.equities_option_chain(\"RELIANCE\")  # Equity option chains\n",
    "curr_option_chain = nse.currency_option_chain(\"USDINR\")  # Currency option chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quote in quotes[\"stocks\"]:\n",
    "    print(\n",
    "        \"{}\\t{}\".format(quote[\"metadata\"][\"identifier\"], quote[\"metadata\"][\"lastPrice\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert nse to ib friendly symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fnos = nse.live_fno()\n",
    "fno_list = {data.get(\"symbol\") for data in raw_fnos.get(\"data\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
