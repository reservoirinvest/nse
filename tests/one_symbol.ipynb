{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get one symbol nakeds\n",
    "\n",
    " - [x] get equity fno list\n",
    " - [x] get equity histories\n",
    " - [x] get index histories\n",
    " - [ ] get equity option histories\n",
    " - [ ] get index option histories\n",
    " - [ ] get lot-sizes\n",
    " - [ ] get market price and volatility\n",
    " - [ ] get chains\n",
    " - [ ] get rim SDs\n",
    " - [ ] retest SDs\n",
    " - [ ] get margins\n",
    " - [ ] pack into symbol objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS CELL SHOULD BE IN ALL VSCODE NOTEBOOKS ##\n",
    "\n",
    "MARKET = 'NSE'\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "# Add `src` to _src.pth in .venv to allow imports in VS Code\n",
    "from sysconfig import get_path\n",
    "from pathlib import Path\n",
    "if 'src' not in Path.cwd().parts:\n",
    "    src_path = str(Path(get_path('purelib')) / '_src.pth')\n",
    "    with open(src_path, 'w') as f:\n",
    "        f.write(str(Path.cwd() / 'src\\n'))\n",
    "\n",
    "# Start the Jupyter loop\n",
    "from ib_async import util\n",
    "util.startLoop()\n",
    "\n",
    "# Set the root\n",
    "from from_root import from_root\n",
    "ROOT = from_root()\n",
    "\n",
    "logger.add(sink=ROOT/ 'log' / 'zscrap.log', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSELive - Jugaad's clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_cache(app_name):\n",
    "    \"\"\"Caches the output for time_out specified. This is done in order to\n",
    "    prevent hitting live quote requests to NSE too frequently. This wrapper\n",
    "    will fetch the quote/live result first time and return the same result for\n",
    "    any calls within 'time_out' seconds.\n",
    "\n",
    "    Logic:\n",
    "        key = concat of args\n",
    "        try:\n",
    "            cached_value = self._cache[key]\n",
    "            if now - self._cache['tstamp'] < time_out\n",
    "                return cached_value['value']\n",
    "        except AttributeError: # _cache attribute has not been created yet\n",
    "            self._cache = {}\n",
    "        finally:\n",
    "            val = fetch-new-value\n",
    "            new_value = {'tstamp': now, 'value': val}\n",
    "            self._cache[key] = new_value\n",
    "            return val\n",
    "\n",
    "    \"\"\"\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        \"\"\"Wrapper function which calls the function only after the timeout,\n",
    "        otherwise returns value from the cache.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get key by just concating the list of args and kwargs values and hope\n",
    "        # that it does not break the code :P \n",
    "        inputs =  [str(a) for a in args] + [str(kwargs[k]) for k in kwargs]\n",
    "        key = app_name.__name__ + '-'.join(inputs)\n",
    "        now = datetime.now()\n",
    "        time_out = self.time_out\n",
    "        try:\n",
    "            cache_obj = self._cache[key]\n",
    "            if now - cache_obj['timestamp'] < timedelta(seconds=time_out):\n",
    "                return cache_obj['value']\n",
    "        except:\n",
    "            self._cache = {}\n",
    "        value = app_name(self, *args, **kwargs)\n",
    "        self._cache[key] = {'value': value, 'timestamp': now}\n",
    "        return value\n",
    "\n",
    "    return wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NSELive:\n",
    "    time_out = 5\n",
    "    base_url = \"https://www.nseindia.com/api\"\n",
    "    page_url = \"https://www.nseindia.com/get-quotes/equity?symbol=LT\"\n",
    "    _routes = {\n",
    "            \"stock_meta\": \"/equity-meta-info\",\n",
    "            \"stock_quote\": \"/quote-equity\",\n",
    "            \"stock_derivative_quote\": \"/quote-derivative\",\n",
    "            \"market_status\": \"/marketStatus\",\n",
    "            \"chart_data\": \"/chart-databyindex\",\n",
    "            \"market_turnover\": \"/market-turnover\",\n",
    "            \"equity_derivative_turnover\": \"/equity-stock\",\n",
    "            \"all_indices\": \"/allIndices\",\n",
    "            \"live_index\": \"/equity-stockIndices\",\n",
    "            \"index_option_chain\": \"/option-chain-indices\",\n",
    "            \"equity_option_chain\": \"/option-chain-equities\",\n",
    "            \"currency_option_chain\": \"/option-chain-currency\",\n",
    "            \"pre_open_market\": \"/market-data-pre-open\",\n",
    "            \"holiday_list\": \"/holiday-master?type=trading\",\n",
    "            \"stock_history\" : \"/historical/cm/equity\", # added by rkv\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.s = requests.Session()\n",
    "        h = {\n",
    "            \"Host\": \"www.nseindia.com\",\n",
    "            \"Referer\": \"https://www.nseindia.com/get-quotes/equity?symbol=SBIN\",\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"pragma\": \"no-cache\",\n",
    "            \"sec-fetch-dest\": \"empty\",\n",
    "            \"sec-fetch-mode\": \"cors\",\n",
    "            \"sec-fetch-site\": \"same-origin\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\",\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "            }\n",
    "        self.s.headers.update(h)\n",
    "        self.s.get(self.page_url)\n",
    "\n",
    "    def split_dates(self, symbol, days:int=365, chunks:int=50) -> list:\n",
    "        end = datetime.today()\n",
    "        periods = int(days/chunks)\n",
    "        start = end-timedelta(days=days)\n",
    "\n",
    "        if days < chunks:\n",
    "            date_ranges = [(start, end)]\n",
    "        else:   \n",
    "            dates = pd.date_range(start, end, periods).date\n",
    "            date_ranges = list(zip(pd.Series(dates), \n",
    "                                   pd.Series(dates).shift(-1)+timedelta(days=-1)))[:-1]\n",
    "\n",
    "        # remove last tuple having period as NaT\n",
    "        if any(pd.isna(e) for element in date_ranges for e in element):\n",
    "            date_ranges = date_ranges[:-1]\n",
    "\n",
    "        series = 'EQ'\n",
    "\n",
    "        ranges = [{'symbol': symbol,\n",
    "        'from': start.strftime('%d-%m-%Y'), \n",
    "        'to': end.strftime('%d-%m-%Y'),\n",
    "        'series': f'[\"{series}\"]'} for start, end in date_ranges]\n",
    "\n",
    "        return ranges \n",
    "\n",
    "    def get(self, route, payload={}):\n",
    "        url = self.base_url + self._routes[route]\n",
    "        r = self.s.get(url, params=payload)\n",
    "        return r.json()\n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_quote\", data) \n",
    "\n",
    "    @live_cache\n",
    "    def stock_quote_fno(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"stock_derivative_quote\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def trade_info(self, symbol):\n",
    "        data = {\"symbol\": symbol, \"section\": \"trade_info\"}\n",
    "        return self.get(\"stock_quote\", data) \n",
    "\n",
    "    @live_cache\n",
    "    def market_status(self):\n",
    "        return self.get(\"market_status\", {})\n",
    "\n",
    "    @live_cache\n",
    "    def chart_data(self, symbol, indices=False):\n",
    "        data = {\"index\" : symbol + \"EQN\"}\n",
    "        if indices:\n",
    "            data[\"index\"] = symbol\n",
    "            data[\"indices\"] = \"true\"\n",
    "        return self.get(\"chart_data\", data)\n",
    "    \n",
    "    @live_cache\n",
    "    def tick_data(self, symbol, indices=False):\n",
    "        return self.chart_data(symbol, indices)\n",
    "\n",
    "    @live_cache\n",
    "    def market_turnover(self):\n",
    "        return self.get(\"market_turnover\")\n",
    "\n",
    "    @live_cache\n",
    "    def eq_derivative_turnover(self, type=\"allcontracts\"):\n",
    "        data = {\"index\": type}\n",
    "        return self.get(\"equity_derivative_turnover\", data)\n",
    "    \n",
    "    @live_cache\n",
    "    def all_indices(self):\n",
    "        return self.get(\"all_indices\")\n",
    "\n",
    "    def live_index(self, symbol=\"NIFTY 50\"):\n",
    "        data = {\"index\" : symbol}\n",
    "        return self.get(\"live_index\", data)\n",
    "    \n",
    "    @live_cache\n",
    "    def index_option_chain(self, symbol=\"NIFTY\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"index_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def equities_option_chain(self, symbol):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"equity_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def currency_option_chain(self, symbol=\"USDINR\"):\n",
    "        data = {\"symbol\": symbol}\n",
    "        return self.get(\"currency_option_chain\", data)\n",
    "\n",
    "    @live_cache\n",
    "    def live_fno(self):\n",
    "        return self.live_index(\"SECURITIES IN F&O\")\n",
    "    \n",
    "    @live_cache\n",
    "    def pre_open_market(self, key=\"NIFTY\"):\n",
    "        data = {\"key\": key}\n",
    "        return self.get(\"pre_open_market\", data)\n",
    "    \n",
    "    @live_cache\n",
    "    def holiday_list(self):\n",
    "        return self.get(\"holiday_list\", {})\n",
    "    \n",
    "    @live_cache\n",
    "    def stock_history(self, symbol, days:int=365, chunks:int=50):\n",
    "        date_ranges = self.split_dates(symbol=symbol, \n",
    "                                       days=days, \n",
    "                                       chunks=chunks)\n",
    "        \n",
    "        result = []\n",
    "        for dr in date_ranges:\n",
    "            result.append(self.get(\"stock_history\", dr))\n",
    "\n",
    "        df = pd.concat([pd.DataFrame(r.get('data')) for r in result], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "        # ...clean columns\n",
    "\n",
    "        mapping = {'CH_SYMBOL': 'nse_symbol',\n",
    "        'TIMESTAMP': 'date',\n",
    "        'CH_OPENING_PRICE': 'open',\n",
    "        'CH_TRADE_HIGH_PRICE': 'high',\n",
    "        'CH_TRADE_LOW_PRICE': 'low',\n",
    "        'CH_CLOSING_PRICE': 'close',\n",
    "        'CH_TOT_TRADED_QTY':'qty_traded',\n",
    "        'CH_TOT_TRADED_VAL':'value_traded',\n",
    "        'CH_TOTAL_TRADES': 'trades',\n",
    "        'VWAP': 'vwap',\n",
    "        'updatedAt': 'extracted_on',\n",
    "        }\n",
    "\n",
    "        df = df[[col for col in mapping.keys() if col in df.columns]].rename(columns=mapping)\n",
    "\n",
    "        # ...convert column datatypes\n",
    "\n",
    "        astype_map = {**{k: 'float' for k in \n",
    "                        ['open', 'high', 'low', 'close', \n",
    "                        'value_traded', 'trades', 'vwap']},\n",
    "                        **{'qty_traded': 'int'}}\n",
    "\n",
    "        df = df.astype(astype_map)\n",
    "\n",
    "        # ...change date columns to utc\n",
    "\n",
    "        replace_cols = ['date', 'extracted_on']\n",
    "        df1 = df[replace_cols].map(lambda x: datetime.fromisoformat(x))\n",
    "        df = df.assign(date=df1.date, extracted_on=df1.extracted_on)\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize NSELive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse = NSELive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Equity fno list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equities = nse.live_fno()\n",
    "\n",
    "# Equities list\n",
    "fno_equities = {kv.get('symbol') for kv in equities.get('data')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Stock History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nse.stock_history('ongc', days=365, chunks=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDXHistories:\n",
    "\n",
    "    time_out = 5\n",
    "    base_url = 'https://niftyindices.com'\n",
    "    url = 'https://niftyindices.com/Backpage.aspx/getHistoricaldatatabletoString'\n",
    "\n",
    "    # prepare `post` header\n",
    "    post_header = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/91.0.4472.77 Safari/537.36',   \n",
    "            'Connection': 'keep-alive',\n",
    "            'sec-ch-ua': '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"',\n",
    "            'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "            'DNT': '1',\n",
    "            'X-Requested-With': 'XMLHttpRequest',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'Content-Type': 'application/json; charset=UTF-8',\n",
    "            'Origin': 'https://niftyindices.com',\n",
    "            'Sec-Fetch-Site': 'same-origin',\n",
    "            'Sec-Fetch-Mode': 'cors',\n",
    "            'Sec-Fetch-Dest': 'empty',\n",
    "            'Referer': 'https://niftyindices.com/reports/historical-data',\n",
    "            'Accept-Language': 'en-US,en;q=0.9,hi;q=0.8',\n",
    "        }\n",
    "\n",
    "    def __init__(self, days:int=365) -> None:\n",
    "        self.s = requests.Session()\n",
    "\n",
    "        # update session with default headers and get the cookies\n",
    "        init_header = requests.utils.default_headers()\n",
    "        init_header.update(\n",
    "            {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/91.0.4472.77 Safari/537.36', \n",
    "            }\n",
    "        )\n",
    "        self.s.headers.update(init_header)\n",
    "        c = self.s.get(url=self.url)\n",
    "        self.cookies = c.cookies\n",
    "\n",
    "    def get(self, payload={}):\n",
    "\n",
    "        r = self.s.post(url=self.url, headers=self.post_header,\n",
    "                        cookies=self.cookies, data=payload, timeout=self.time_out)\n",
    "        \n",
    "        return r.json()\n",
    "\n",
    "    def make_histories(self, days:int=365):\n",
    "        \"\"\"Makes histories for NIFTY50 and BANKNIFTY, based on number of days provided\"\"\"\n",
    "\n",
    "        # build the date buckets and nse index symbols\n",
    "\n",
    "        self.days = days # for the record\n",
    "\n",
    "        end = datetime.today()\n",
    "        chunks = 100\n",
    "        periods = int(days/chunks)\n",
    "        start = end-timedelta(days=days)\n",
    "\n",
    "        if days < chunks:\n",
    "            date_ranges = [(start, end)]\n",
    "        else:   \n",
    "            dates = pd.date_range(start, end, periods).date\n",
    "            date_ranges = list(zip(pd.Series(dates), pd.Series(dates).shift(-1)+timedelta(days=-1)))[:-1]\n",
    "\n",
    "        # remove last tuple having period as NaT\n",
    "        if any(pd.isna(e) for element in date_ranges for e in element):\n",
    "            date_ranges = date_ranges[:-1]\n",
    "\n",
    "        idx_symbols =['Nifty Bank', 'Nifty 50']\n",
    "\n",
    "        # organize the payloads\n",
    "        payloads = [{'cinfo': str({'name': idx_symbol,\n",
    "                                'startDate': s.strftime('%d-%b-%Y'),\n",
    "                                'endDate': e.strftime('%d-%b-%Y'),\n",
    "                                'indexName': idx_symbol})} for s, e in date_ranges for idx_symbol in idx_symbols]\n",
    "        # get the raw jsons\n",
    "        results = []\n",
    "\n",
    "        for payload in tqdm(payloads):\n",
    "            r = self.get(payload=json.dumps(payload))\n",
    "            results.append(r)\n",
    "\n",
    "        # build the dataframe\n",
    "        df = pd.concat([pd.DataFrame(json.loads(r.get('d'))) for r in results],\n",
    "                ignore_index=True)\n",
    "\n",
    "        # clean the df\n",
    "\n",
    "        #...drop unnecessary columns\n",
    "\n",
    "        df = df.drop(df.columns[[0, 1]], axis=1)\n",
    "\n",
    "        #...rename\n",
    "        df.columns=['nse_symbol', 'date', 'open', \n",
    "                    'high', 'low', 'close']\n",
    "\n",
    "        #...convert nse_symbol to IB's symbol\n",
    "        df = pd.concat([df.nse_symbol.map({'Nifty Bank': 'BANKNIFTY', \n",
    "                        'Nifty 50': 'NIFTY50'}).rename('symbol'), \n",
    "                    df], axis=1)\n",
    "        #...convert dates to UTC 3:30 PM IST (market close time)\n",
    "        dates = df.date\n",
    "\n",
    "        # .....specify desired timezone offset (Asia/Kolkata is UTC+5:30)\n",
    "        tz_offset = timezone(timedelta(hours=5, minutes=30))  \n",
    "\n",
    "        # .....parse dates with specified format and set time to 3:30 PM IST\n",
    "        datetime_series = pd.to_datetime(dates, format='%d %b %Y') + pd.Timedelta(hours=15, minutes=30)\n",
    "\n",
    "        # .....convert to UTC with desired offset\n",
    "        utc_dates = datetime_series.dt.tz_localize(tz_offset)\n",
    "\n",
    "        df = df.assign(date=utc_dates)\n",
    "\n",
    "        # .....convert ohlc to numeric\n",
    "        convert_dict = {k: 'float' for k in \n",
    "                        ['open', 'high', 'low', 'close']}\n",
    "\n",
    "        df = df.astype(convert_dict)\n",
    "\n",
    "        # .....sort by date\n",
    "        df.sort_values(['nse_symbol', 'date'], inplace=True, ignore_index=True)\n",
    "\n",
    "        # .....add extract_date\n",
    "        now = datetime.now()\n",
    "        utc_now = now.astimezone(timezone.utc)\n",
    "        df = df.assign(extracted_on=utc_now)\n",
    "\n",
    "        self.hist = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Index Histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = IDXHistories()\n",
    "\n",
    "idx.make_histories() #give number of days needed\n",
    "\n",
    "idx.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert nse to ib friendly symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_fnos = nse.live_fno()\n",
    "fno_list = {data.get('symbol') for data in raw_fnos.get('data')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = {\"M&M\": \"MM\",\n",
    "\"M&MFIN\": \"MMFIN\",\n",
    "\"L&TFH\": \"LTFH\",\n",
    "\"NIFTY\": \"NIFTY50\"}\n",
    "\n",
    "list_without_percent_sign = list(map(subs.get, fno_list, fno_list))\n",
    "\n",
    "# fix length to 9 characters\n",
    "ib_equity_fnos = [s[:9] for s in list_without_percent_sign]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
